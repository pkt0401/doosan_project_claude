import streamlit as st
import pandas as pd
import numpy as np
import faiss
import openai
import re
import os
from PIL import Image
from sklearn.model_selection import train_test_split

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ë° ì‚¬ê³  ì˜ˆì¸¡",
    page_icon="ğŸ› ï¸",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #0D47A1;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .info-text {
        font-size: 1rem;
        color: #424242;
        margin-bottom: 1rem;
    }
    .highlight {
        background-color: #e3f2fd;
        padding: 5px;
        border-radius: 5px;
    }
    .result-box {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin-top: 10px;
        margin-bottom: 10px;
        border-left: 5px solid #4CAF50;
    }
    .phase-badge {
        background-color: #4CAF50;
        color: white;
        padding: 5px 10px;
        border-radius: 15px;
        font-size: 0.8rem;
        margin-right: 10px;
    }
</style>
""", unsafe_allow_html=True)

# í—¤ë” í‘œì‹œ
st.markdown('<div class="main-header">AI í™œìš© ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ë° ì‚¬ê³  ì˜ˆì¸¡</div>', unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "index" not in st.session_state:
    st.session_state.index = None
if "embeddings" not in st.session_state:
    st.session_state.embeddings = None
if "retriever_pool_df" not in st.session_state:
    st.session_state.retriever_pool_df = None

# íƒ­ ì„¤ì •
tabs = st.tabs(["ì‹œìŠ¤í…œ ê°œìš”", "ìœ„í—˜ì„± í‰ê°€ (Phase 1)", "ê°œì„ ëŒ€ì±… ìƒì„± (Phase 2)"])

# ------------------ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ------------------

def determine_grade(value):
    if 16 <= value <= 25:
        return 'A'
    elif 10 <= value <= 15:
        return 'B'
    elif 5 <= value <= 9:
        return 'C'
    elif 3 <= value <= 4:
        return 'D'
    elif 1 <= value <= 2:
        return 'E'
    else:
        return 'ì•Œ ìˆ˜ ì—†ìŒ'


def load_data(selected_dataset_name):
    try:
        df = pd.read_excel(f"{selected_dataset_name}.xlsx")
        if 'ì‚­ì œ Del' in df.columns:
            df = df.drop(['ì‚­ì œ Del'], axis=1)
        df = df.iloc[1:]
        df = df.rename(columns={df.columns[4]: 'ë¹ˆë„', df.columns[5]: 'ê°•ë„'})
        df['T'] = pd.to_numeric(df.iloc[:,4]) * pd.to_numeric(df.iloc[:,5])
        df = df.iloc[:,:7]
        df.rename(
            columns={
                'ì‘ì—…í™œë™ ë° ë‚´ìš©\nWork & Contents':'ì‘ì—…í™œë™ ë° ë‚´ìš©',
                'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥\nHazard & Risk':'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥',
                'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥\nDamage & Effect':'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥'
            }, inplace=True)
        df = df.rename(columns={df.columns[6]:'T'})
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.warning("Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        data = {
            "ì‘ì—…í™œë™ ë° ë‚´ìš©":["Shoring Installation","In and Out of materials","Transport / Delivery","Survey and Inspection"],
            "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥":["Fall and collision due to unstable ground","Overturning of transport vehicle","Collision between transport vehicle","Personnel fall while inspecting"],
            "í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥":["Injury","Equipment damage","Collision injury","Fall injury"],
            "ë¹ˆë„":[3,3,3,2],"ê°•ë„":[2,3,5,3]
        }
        df = pd.DataFrame(data)
        df['T'] = df['ë¹ˆë„']*df['ê°•ë„']
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)
        return df


def embed_texts_with_openai(texts, model="text-embedding-3-large", api_key=None):
    if api_key:
        openai.api_key = api_key
    embeddings = []
    progress_bar = st.progress(0)
    total = len(texts)
    for idx, text in enumerate(texts):
        try:
            text = str(text).replace("\n"," ")
            response = openai.Embedding.create(model=model, input=[text])
            embeddings.append(response["data"][0]["embedding"])
        except:
            embeddings.append([0]*1536)
        progress_bar.progress((idx+1)/total)
    return embeddings


def generate_with_gpt(prompt, api_key=None, model="gpt-4o"):
    if api_key:
        openai.api_key = api_key
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role":"system","content":"ìœ„í—˜ì„± í‰ê°€ ë° ê°œì„ ëŒ€ì±… ìƒì„±ì„ ë•ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                      {"role":"user","content":prompt}],
            temperature=0.0,
            max_tokens=250
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        st.error(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ----- Phase1 ì „ìš© Prompt/Parser (ìœ í•´ìœ„í—˜ìš”ì¸ ì˜ˆì¸¡) -----

def construct_prompt_phase1_for_hazard(retrieved_docs, query_activity):
    prompt = ""
    for i, row in enumerate(retrieved_docs.itertuples(),1):
        activity = getattr(row,'content')
        hazard = getattr(row,'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥')
        prompt += f"ì˜ˆì‹œ {i}:\nì…ë ¥: {activity}\nì¶œë ¥: {hazard}\n
"
    prompt += (
        f"ì…ë ¥: {query_activity}\n"
        "ìœ„ ì‘ì—…í™œë™ ë° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ í•´ìœ„í—˜ìš”ì¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì˜ˆì¸¡í•˜ì„¸ìš”.\n"
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:\n"
        '{"ìœ í•´ìœ„í—˜ìš”ì¸":"ì—¬ê¸°ì— ì˜ˆì¸¡ ê²°ê³¼"}\n'
    )
    return prompt


def parse_gpt_output_phase1_for_hazard(gpt_output):
    try:
        m = re.search(r'\{.*\}', gpt_output, re.DOTALL)
        if not m:
            return None
        data = re.json.loads(m.group())
        return data.get("ìœ í•´ìœ„í—˜ìš”ì¸")
    except:
        return None

# ----- Phase2: ê°œì„ ëŒ€ì±… ìƒì„± ê´€ë ¨ í•¨ìˆ˜ -----
def compute_rrr(T_before, T_after):
    if T_before == 0:
        return 0.0
    return ((T_before - T_after) / T_before) * 100.0


def construct_prompt_phase2(retrieved_docs, activity_text, hazard_text, freq, intensity, T, target_language="Korean"):
    example_section = ""
    examples_added = 0
    for _, row in retrieved_docs.iterrows():
        try:
            improvement_plan = ""
            for field in ['ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ','ê°œì„ ëŒ€ì±…','ê°œì„ ë°©ì•ˆ']:
                if field in row and pd.notna(row[field]):
                    improvement_plan = row[field]
                    break
            if not improvement_plan:
                continue
            orig_f = int(row['ë¹ˆë„'])
            orig_i = int(row['ê°•ë„'])
            orig_T = orig_f * orig_i
            imp_f, imp_i, imp_T = 1,1,1
            for pat in [('ê°œì„  í›„ ë¹ˆë„','ê°œì„  í›„ ê°•ë„','ê°œì„  í›„ T'),('ê°œì„ ë¹ˆë„','ê°œì„ ê°•ë„','ê°œì„ T')]:
                if all(p in row for p in pat):
                    imp_f = int(row[pat[0]]); imp_i = int(row[pat[1]]); imp_T = int(row[pat[2]]); break
            example_section += (
                "Example:\n"
                f"Input (Activity): {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}\n"
                f"Input (Hazard): {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}\n"
                f"Input (Original Frequency): {orig_f}\n"
                f"Input (Original Intensity): {orig_i}\n"
                f"Input (Original T): {orig_T}\n"
                "Output (Improvement Plan and Risk Reduction) in JSON:\n"
                "{\n"
                f"  \"ê°œì„ ëŒ€ì±…\": \"{improvement_plan}\",\n"
                f"  \"ê°œì„  í›„ ë¹ˆë„\": {imp_f},\n"
                f"  \"ê°œì„  í›„ ê°•ë„\": {imp_i},\n"
                f"  \"ê°œì„  í›„ T\": {imp_T},\n"
                f"  \"T ê°ì†Œìœ¨\": {compute_rrr(orig_T, imp_T):.2f}\n"
                "}\n\n"
            )
            examples_added += 1
            if examples_added >= 3:
                break
        except:
            continue
    if examples_added == 0:
        example_section = "... ê¸°ë³¸ ì˜ˆì‹œ ..."
    prompt = (
        f"{example_section}"
        "Now here is a new input:\n"
        f"Input (Activity): {activity_text}\n"
        f"Input (Hazard): {hazard_text}\n"
        f"Input (Original Frequency): {freq}\n"
        f"Input (Original Intensity): {intensity}\n"
        f"Input (Original T): {T}\n\n"
        "Please provide the output in JSON format with these keys:\n"
        "{\n"
        "  \"ê°œì„ ëŒ€ì±…\": \"í•­ëª©ë³„ ê°œì„ ëŒ€ì±… ë¦¬ìŠ¤íŠ¸\", \n"
        "  \"ê°œì„  í›„ ë¹ˆë„\": (an integer in [1..5]),\n"
        "  \"ê°œì„  í›„ ê°•ë„\": (an integer in [1..5]),\n"
        "  \"ê°œì„  í›„ T\": (Improved Frequency * Improved Severity),\n"
        "  \"T ê°ì†Œìœ¨\": (percentage of risk reduction)\n"
        "}\n\n"
        f"Please write the improvement measures (ê°œì„ ëŒ€ì±…) in {target_language}.\n"
        "Provide at least 3 specific improvement measures as a numbered list.\n"
        "Make sure to return only valid JSON.\n"
        "Output:\n"
    )
    return prompt


def parse_gpt_output_phase2(gpt_output):
    try:
        pattern = re.compile(r"```json(.*?)```", re.DOTALL)
        m = pattern.search(gpt_output)
        json_str = m.group(1).strip() if m else gpt_output.replace("```","")
        return pd.json.loads(json_str)
    except Exception as e:
        st.error(f"JSON íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ë°ì´í„°ì…‹ ì˜µì…˜
dataset_options = {
    "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)":"SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)",
    "Civil (í† ëª©)":"Civil (í† ëª©)",
    "Marine (í† ëª©)":"Marine (í† ëª©)",
    "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)":"SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)",
    "SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)":"SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)"
}

# ì‹œìŠ¤í…œ ê°œìš” íƒ­
with tabs[0]:
    st.markdown('<div class="sub-header">LLM ê¸°ë°˜ ìœ„í—˜ì„±í‰ê°€ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)
    # ... ê°œìš” ë‚´ìš© ìƒëµ ê°€ëŠ¥

# Phase 1 íƒ­
with tabs[1]:
    st.markdown('<div class="sub-header">ìœ„í—˜ì„± í‰ê°€ ìë™í™” (Phase 1)</div>', unsafe_allow_html=True)
    api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="api_key_phase1")
    selected_dataset_name = st.selectbox("ë°ì´í„°ì…‹ ì„ íƒ", list(dataset_options.keys()), key="dataset_selector_phase1")
    if st.button("ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„±", key="load_data_phase1"):
        if not api_key:
            st.warning("ê³„ì†í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì¸ë±ìŠ¤ë¥¼ êµ¬ì„±í•˜ëŠ” ì¤‘...'):
                df = load_data(dataset_options[selected_dataset_name])
                train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)
                retriever_pool_df = train_df.copy()
                retriever_pool_df['content'] = retriever_pool_df['ì‘ì—…í™œë™ ë° ë‚´ìš©'].astype(str)
                texts = retriever_pool_df['content'].tolist()
                max_texts = min(len(texts), 10)
                st.info(f"ë°ëª¨: {max_texts}ê°œ í…ìŠ¤íŠ¸ ì„ë² ë”© ì²˜ë¦¬")
                embeddings = embed_texts_with_openai(texts[:max_texts], api_key=api_key)
                embeddings_array = np.array(embeddings, dtype='float32')
                faiss_index = faiss.IndexFlatL2(embeddings_array.shape[1])
                faiss_index.add(embeddings_array)
                st.session_state.index = faiss_index
                st.session_state.embeddings = embeddings_array
                st.session_state.retriever_pool_df = retriever_pool_df.iloc[:max_texts]
                st.success("ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„± ì™„ë£Œ!")
    if st.session_state.index is None:
        st.warning("ë¨¼ì € ì¸ë±ìŠ¤ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.")
    else:
        with st.form("user_input_form"):
            user_activity = st.text_input("ì‘ì—…í™œë™ ë° ë‚´ìš©:", key="form_user_activity")
            submitted = st.form_submit_button("ìœ í•´ìœ„í—˜ìš”ì¸ ì˜ˆì¸¡í•˜ê¸°")
        if submitted:
            if not user_activity:
                st.warning("ì‘ì—…í™œë™ ë° ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                    query_embedding = embed_texts_with_openai([user_activity], api_key=api_key)[0]
                    distances, indices = st.session_state.index.search(np.array([query_embedding],dtype='float32'), 3)
                    retrieved_docs = st.session_state.retriever_pool_df.iloc[indices[0]]
                    prompt = construct_prompt_phase1_for_hazard(retrieved_docs, user_activity)
                    generated_output = generate_with_gpt(prompt, api_key=api_key)
                    hazard_pred = parse_gpt_output_phase1_for_hazard(generated_output)
                    st.markdown(f"**ì‘ì—…í™œë™ ë° ë‚´ìš©:** {user_activity}")
                    st.markdown(f"**ì˜ˆì¸¡ëœ ìœ í•´ìœ„í—˜ìš”ì¸:** {hazard_pred}")
                    st.markdown("#### ìœ ì‚¬ ì‚¬ë¡€")
                    for _, row in retrieved_docs.iterrows():
                        st.markdown(f"- **ì‘ì—…í™œë™ ë° ë‚´ìš©:** {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}")
                        st.markdown(f"  - ìœ í•´ìœ„í—˜ìš”ì¸: {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}")

# Phase2 íƒ­ ì „ì²´ ì½”ë“œ
with tabs[2]:
    st.markdown('<div class="sub-header">ê°œì„ ëŒ€ì±… ìë™ ìƒì„± (Phase 2)</div>', unsafe_allow_html=True)
    api_key_phase2 = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="api_key_phase2")
    target_language = st.selectbox(
        "ê°œì„ ëŒ€ì±… ì–¸ì–´ ì„ íƒ:",
        options=["Korean", "English", "Chinese"],
        index=0,
        key="target_language"
    )
    input_method = st.radio(
        "ì…ë ¥ ë°©ì‹ ì„ íƒ:",
        options=["Phase 1 í‰ê°€ ê²°ê³¼ ì‚¬ìš©", "ì§ì ‘ ì…ë ¥"],
        index=0,
        key="input_method"
    )
    if input_method == "Phase 1 í‰ê°€ ê²°ê³¼ ì‚¬ìš©":
        if hasattr(st.session_state, 'last_assessment'):
            last_assessment = st.session_state.last_assessment
            st.markdown("### Phase 1 í‰ê°€ ê²°ê³¼")
            st.markdown(f"**ì‘ì—…í™œë™:** {last_assessment['activity']}")
            st.markdown(f"**ìœ í•´ìœ„í—˜ìš”ì¸:** {last_assessment['hazard']}")
            st.markdown(
                f"**ìœ„í—˜ë„:** ë¹ˆë„ {last_assessment['frequency']}, ê°•ë„ {last_assessment['intensity']}, Tê°’ {last_assessment['T']} (ë“±ê¸‰ {last_assessment['grade']})"
            )
            activity_text = last_assessment['activity']
            hazard_text = last_assessment['hazard']
            frequency = last_assessment['frequency']
            intensity = last_assessment['intensity']
            T_value = last_assessment['T']
        else:
            st.warning("ë¨¼ì € Phase 1ì—ì„œ ìœ„í—˜ì„± í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
            activity_text = hazard_text = None
            frequency = intensity = T_value = None
    else:
        col1, col2 = st.columns(2)
        with col1:
            activity_text = st.text_input("ì‘ì—…í™œë™:", key="direct_activity")
            hazard_text = st.text_input("ìœ í•´ìœ„í—˜ìš”ì¸:", key="direct_hazard")
        with col2:
            frequency = st.number_input("ë¹ˆë„ (1-5):", min_value=1, max_value=5, value=3, key="direct_freq")
            intensity = st.number_input("ê°•ë„ (1-5):", min_value=1, max_value=5, value=3, key="direct_intensity")
            T_value = frequency * intensity
            st.markdown(f"**Tê°’:** {T_value} (ë“±ê¸‰: {determine_grade(T_value)})")
    if st.button("ê°œì„ ëŒ€ì±… ìƒì„±", key="generate_improvement") and activity_text and hazard_text:
        if not api_key_phase2:
            st.warning("ê³„ì†í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ê°œì„ ëŒ€ì±…ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                if st.session_state.retriever_pool_df is None or st.session_state.index is None:
                    df = load_data("Civil (í† ëª©)")
                    retriever_pool_df = df.sample(min(5, len(df)))
                    retrieved_docs = retriever_pool_df.sample(min(3, len(retriever_pool_df)))
                else:
                    retriever_pool_df = st.session_state.retriever_pool_df
                    query_text = f"{activity_text} {hazard_text}"
                    query_embedding = embed_texts_with_openai([query_text], api_key=api_key_phase2)[0]
                    distances, indices = st.session_state.index.search(np.array([query_embedding], dtype='float32'), 3)
                    retrieved_docs = retriever_pool_df.iloc[indices[0]]
                prompt = construct_prompt_phase2(
                    retrieved_docs, activity_text, hazard_text,
                    frequency, intensity, T_value, target_language
                )
                generated_output = generate_with_gpt(prompt, api_key=api_key_phase2)
                parsed = parse_gpt_output_phase2(generated_output)
                if parsed:
                    improvement_plan = parsed.get("ê°œì„ ëŒ€ì±…", "")
                    imp_freq = parsed.get("ê°œì„  í›„ ë¹ˆë„", 1)
                    imp_int = parsed.get("ê°œì„  í›„ ê°•ë„", 1)
                    imp_T = parsed.get("ê°œì„  í›„ T", imp_freq*imp_int)
                    rrr = parsed.get("T ê°ì†Œìœ¨", compute_rrr(T_value, imp_T))
                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.markdown("#### ê°œì„ ëŒ€ì±… ìƒì„± ê²°ê³¼")
                    c1, c2 = st.columns([3,2])
                    with c1:
                        st.markdown("##### ê°œì„ ëŒ€ì±…")
                        st.markdown(improvement_plan)
                    with c2:
                        comp_df = pd.DataFrame({
                            'í•­ëª©':['ë¹ˆë„','ê°•ë„','Tê°’','ìœ„í—˜ë“±ê¸‰'],
                            'ê°œì„  ì „':[frequency,intensity,T_value,determine_grade(T_value)],
                            'ê°œì„  í›„':[imp_freq,imp_int,imp_T,determine_grade(imp_T)]
                        })
                        st.table(comp_df)
                        st.metric("ìœ„í—˜ ê°ì†Œìœ¨ (RRR)", f"{rrr:.2f}%")
                    st.markdown('</div>', unsafe_allow_html=True)
                    st.markdown("#### ìœ„í—˜ë„(Tê°’) ë³€í™”")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**ê°œì„  ì „ Tê°’:**")
                        st.progress(T_value/25)
                    with col2:
                        st.markdown("**ê°œì„  í›„ Tê°’:**")
                        st.progress(imp_T/25)
                else:
                    st.error("ê°œì„ ëŒ€ì±… ìƒì„± ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.write(generated_output)

# í‘¸í„°
st.markdown('<hr style="margin-top:50px;">', unsafe_allow_html=True)
st.markdown('<div style="display:flex;justify-content:space-between;align-items:center;">', unsafe_allow_html=True)
col1, col2 = st.columns(2)
with col1:
    if os.path.exists("cau.png"): st.image(Image.open("cau.png"), width=150)
with col2:
    if os.path.exists("doosan.png"): st.image(Image.open("doosan.png"), width=180)
st.markdown('</div>', unsafe_allow_html=True)
