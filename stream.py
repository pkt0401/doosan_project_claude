import os
import re
import json
import time
from typing import List, Tuple, Dict

import streamlit as st
import pandas as pd
import numpy as np
import faiss
import openai
from PIL import Image
from sklearn.model_selection import train_test_split

# -----------------------------------------------------------------------------
# 1. LANGUAGE & UI TEXT MAPPINGS
# -----------------------------------------------------------------------------
FLAG = {"Korean": "ğŸ‡°ğŸ‡·", "English": "ğŸ‡ºğŸ‡¸", "Chinese": "ğŸ‡¨ğŸ‡³"}

SYSTEM_TEXT = {
    # (ê¸°ì¡´ ë”•ì…”ë„ˆë¦¬ì—ì„œ Overview, Labels ë“± ìµœì†Œí•œë§Œ ìœ ì§€)
    "Korean": {
        "title": "Artificial Intelligence Risk Assessment",
        "input_header": "ì‘ì—…í™œë™ ë° ë‚´ìš© ì…ë ¥",
        "api_key_label": "OpenAI APIÂ Key ì…ë ¥",
        "run_btn": "ìœ„í—˜ì„± í‰ê°€ ì‹¤í–‰",
        "embedding_msg": "ì„ë² ë”© ì§„í–‰ ì¤‘... (ë¬¸ì„œ {cur}/{total})",
        "similar_cases": "ìœ ì‚¬ ì‚¬ë¡€",
        "result_header": "AI Risk Assessment ê²°ê³¼",
        "improvement_header": "ê°œì„ ëŒ€ì±… ë° ìœ„í—˜ë„ ê°œì„ ",
        "export_btn": "Excel Export",
        "hazard_label": "ì˜ˆì¸¡ëœ ìœ í•´ìœ„í—˜ìš”ì¸",
        "grade": "ìœ„í—˜ë“±ê¸‰",
    },
    "English": {
        "title": "Artificial Intelligence Risk Assessment",
        "input_header": "Work activity",
        "api_key_label": "OpenAI API Key",
        "run_btn": "Run Assessment",
        "embedding_msg": "Embedding documents... ({cur}/{total})",
        "similar_cases": "Similar cases",
        "result_header": "AI Risk Assessment Results",
        "improvement_header": "Improvement Plan & Risk Mitigation",
        "export_btn": "Excel Export",
        "hazard_label": "Predicted hazard",
        "grade": "Risk grade",
    },
    "Chinese": {
        "title": "Artificial Intelligence Risk Assessment",
        "input_header": "å·¥ä½œæ´»åŠ¨",
        "api_key_label": "OpenAI API å¯†é’¥",
        "run_btn": "å¼€å§‹è¯„ä¼°",
        "embedding_msg": "æ­£åœ¨ç”ŸæˆåµŒå…¥... ({cur}/{total})",
        "similar_cases": "ç›¸ä¼¼æ¡ˆä¾‹",
        "result_header": "AI é£é™©è¯„ä¼°ç»“æœ",
        "improvement_header": "æ”¹è¿›æªæ–½ä¸é£é™©é™ä½",
        "export_btn": "Excel å¯¼å‡º",
        "hazard_label": "é¢„æµ‹çš„å±å®³",
        "grade": "é£é™©ç­‰çº§",
    },
}

# -----------------------------------------------------------------------------
# 2. PAGE CONFIG & GLOBAL SESSION STATE
# -----------------------------------------------------------------------------
st.set_page_config(page_title="AI Risk Assessment", page_icon="ğŸ› ï¸", layout="wide")

if "lang" not in st.session_state:
    st.session_state.lang = "Korean"
if "faiss_index" not in st.session_state:
    st.session_state.faiss_index = None
if "retriever_df" not in st.session_state:
    st.session_state.retriever_df = None
if "embeddings" not in st.session_state:
    st.session_state.embeddings = None
if "last_result" not in st.session_state:
    st.session_state.last_result = None

# -----------------------------------------------------------------------------
# 3. TOP BAR  (Language selector + Flags)
# -----------------------------------------------------------------------------

# We draw the top bar using columns so that the language dropdown sticks to the right.
bar_col1, bar_col2 = st.columns([8, 1])
with bar_col2:
    choice = st.selectbox("Language", options=list(SYSTEM_TEXT.keys()),
                          format_func=lambda x: f"{FLAG[x]}Â Â {x}",
                          index=list(SYSTEM_TEXT.keys()).index(st.session_state.lang))
    st.session_state.lang = choice
TXT = SYSTEM_TEXT[st.session_state.lang]

# -----------------------------------------------------------------------------
# 4. HEADER
# -----------------------------------------------------------------------------
st.markdown(f"<h1 style='text-align:center;color:#1565C0;margin-bottom:0.2em'>{TXT['title']}</h1>", unsafe_allow_html=True)

# Logos (ì¢Œì¸¡: ë‘ì‚° / ìš°ì¸¡: ì¤‘ì•™ëŒ€)
logo_col1, _, logo_col2 = st.columns([1, 8, 1])
with logo_col1:
    if os.path.exists("doosan.png"):
        st.image("doosan.png", width=120)
with logo_col2:
    if os.path.exists("cau.png"):
        st.image("cau.png", width=90)

# -----------------------------------------------------------------------------
# 5. SIDEBAR  (Input controls)
# -----------------------------------------------------------------------------
with st.sidebar:
    st.header(FLAG[st.session_state.lang] + "  " + TXT["input_header"])
    api_key = st.text_input(TXT["api_key_label"], type="password")
    user_activity = st.text_area("", height=120)
    run = st.button(TXT["run_btn"], use_container_width=True)

# -----------------------------------------------------------------------------
# 6. DATA LOADING & EMBEDDING UTILS
# -----------------------------------------------------------------------------

def determine_grade(t: int, lang: str) -> str:
    if 16 <= t <= 25:
        return "A"
    if 10 <= t <= 15:
        return "B"
    if 5 <= t <= 9:
        return "C"
    if 3 <= t <= 4:
        return "D"
    if 1 <= t <= 2:
        return "E"
    return "Unknown" if lang != "Korean" else "ì•Œ ìˆ˜ ì—†ìŒ"

@st.cache_data(show_spinner=False)
def load_dataset() -> pd.DataFrame:
    """Load Excel or fallback sample."""
    try:
        df = pd.read_excel("Civil (í† ëª©).xlsx")  # ì‹¤ì œ íŒŒì¼ëª…
        if "ì‚­ì œ Del" in df.columns:
            df = df.drop(["ì‚­ì œ Del"], axis=1)
        df = df.iloc[1:]
        df = df.rename(columns={df.columns[4]: "ë¹ˆë„", df.columns[5]: "ê°•ë„", df.columns[6]: "T"})
        df["T"] = pd.to_numeric(df["ë¹ˆë„"]) * pd.to_numeric(df["ê°•ë„"])
        df["ë“±ê¸‰"] = df["T"].apply(lambda x: determine_grade(int(x), "Korean"))
        return df
    except Exception:
        # Minimal sample â€“ production should replace with real file.
        _samp = {
            "ì‘ì—…í™œë™ ë° ë‚´ìš©": ["Lifting operation", "Excavation work"],
            "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥": ["Material fall", "Wall collapse"],
            "í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥": ["Injury", "Injury"],
            "ë¹ˆë„": [3, 4],
            "ê°•ë„": [4, 4],
        }
        df = pd.DataFrame(_samp)
        df["T"] = df["ë¹ˆë„"] * df["ê°•ë„"]
        df["ë“±ê¸‰"] = df["T"].apply(lambda x: determine_grade(int(x), "Korean"))
        return df

def build_embeddings(df: pd.DataFrame, api_key: str) -> Tuple[faiss.IndexFlatL2, np.ndarray]:
    """Embed full dataset and return a FAISS index."""
    openai.api_key = api_key
    contents = df.apply(lambda r: " ".join(r.astype(str)), axis=1).tolist()
    embeddings: List[List[float]] = []
    pb = st.progress(0, text=TXT["embedding_msg"].format(cur=0, total=len(contents)))
    for idx, text in enumerate(contents, 1):
        try:
            resp = openai.Embedding.create(model="text-embedding-3-large", input=[text])
            embeddings.append(resp["data"][0]["embedding"])
        except Exception as e:
            st.error(f"Embedding error @ row {idx}: {e}")
            embeddings.append([0.0] * 1536)
        pb.progress(idx / len(contents), text=TXT["embedding_msg"].format(cur=idx, total=len(contents)))
    emb_arr = np.array(embeddings, dtype="float32")
    idx = faiss.IndexFlatL2(emb_arr.shape[1])
    idx.add(emb_arr)
    return idx, emb_arr

# -----------------------------------------------------------------------------
# 7. GPT HELPERS
# -----------------------------------------------------------------------------

def gpt_chat(prompt: str, api_key: str, lang: str, max_tokens: int = 256) -> str:
    openai.api_key = api_key
    system = {
        "Korean": "ë‹¹ì‹ ì€ ê±´ì„¤ ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ê³µí•™ì  ìˆ˜ì¹˜ë¥¼ í¬í•¨í•œ êµ¬ì²´ì  ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.",
        "English": "You are a construction safety expert. Answer in English with engineeringâ€‘level, quantitative guidance.",
        "Chinese": "ä½ æ˜¯ä¸€åå»ºç­‘å®‰å…¨ä¸“å®¶ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ç»™å‡ºå…·æœ‰å·¥ç¨‹é‡åŒ–æŒ‡æ ‡çš„å…·ä½“æªæ–½ã€‚",
    }[lang]
    resp = openai.ChatCompletion.create(
        model="gpt-4o", temperature=0.0, max_tokens=max_tokens,
        messages=[{"role": "system", "content": system}, {"role": "user", "content": prompt}],
    )
    return resp["choices"][0]["message"]["content"].strip()

# -----------------------------------------------------------------------------
# 8. PROMPT BUILDERS  (Hazard + Risk + Improvement)
# -----------------------------------------------------------------------------

def prompt_hazard(examples: pd.DataFrame, activity: str, lang: str) -> str:
    intro = {
        "Korean": "ë‹¤ìŒì€ ì‘ì—…í™œë™ê³¼ ìœ í•´ìœ„í—˜ìš”ì¸ ì˜ˆì‹œì…ë‹ˆë‹¤:\n\n",
        "English": "Examples of work activities and hazards:\n\n",
        "Chinese": "ä»¥ä¸‹æ˜¯å·¥ä½œæ´»åŠ¨åŠå±å®³ç¤ºä¾‹ï¼š\n\n",
    }[lang]
    fmt = {
        "Korean": "ì˜ˆì‹œ {i}: ì‘ì—…í™œë™: {a}\nìœ í•´ìœ„í—˜ìš”ì¸: {h}\n\n",
        "English": "Example {i}: Activity: {a}\nHazard: {h}\n\n",
        "Chinese": "ç¤ºä¾‹ {i}: å·¥ä½œæ´»åŠ¨: {a}\nå±å®³: {h}\n\n",
    }[lang]
    q = {
        "Korean": "ë‹¤ìŒ ì‘ì—…í™œë™ì˜ ìœ í•´ìœ„í—˜ìš”ì¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ì‹­ì‹œì˜¤:\nì‘ì—…í™œë™: {act}\nìœ í•´ìœ„í—˜ìš”ì¸:",
        "English": "Predict the specific hazard for the following activity:\nActivity: {act}\nHazard:",
        "Chinese": "è¯·é¢„æµ‹ä»¥ä¸‹å·¥ä½œæ´»åŠ¨çš„å…·ä½“å±å®³ï¼š\nå·¥ä½œæ´»åŠ¨: {act}\nå±å®³:",
    }[lang]
    prompt = intro
    for i, row in enumerate(examples.itertuples(), 1):
        prompt += fmt.format(i=i, a=row._1, h=row._2)
    prompt += q.format(act=activity)
    return prompt

def prompt_risk(examples: pd.DataFrame, activity: str, hazard: str, lang: str) -> str:
    json_tpl = {
        "Korean": "{\"ë¹ˆë„\": ìˆ«ì, \"ê°•ë„\": ìˆ«ì, \"T\": ìˆ«ì}",
        "English": "{\"frequency\": number, \"intensity\": number, \"T\": number}",
        "Chinese": "{\"é¢‘ç‡\": æ•°å­—, \"å¼ºåº¦\": æ•°å­—, \"T\": æ•°å­—}",
    }[lang]
    fmt_ex = {
        "Korean": "ì˜ˆì‹œ {i}: ì…ë ¥: {inp}\nì¶œë ¥: {out}\n\n",
        "English": "Example {i}: Input: {inp}\nOutput: {out}\n\n",
        "Chinese": "ç¤ºä¾‹ {i}: è¾“å…¥: {inp}\nè¾“å‡º: {out}\n\n",
    }[lang]
    prompt = ""
    for i, row in enumerate(examples.itertuples(), 1):
        inp = f"{row._1} - {row._2}"
        out = f"{{\"ë¹ˆë„\": {row.ë¹ˆë„}, \"ê°•ë„\": {row.ê°•ë„}, \"T\": {row.T}}}"
        prompt += fmt_ex.format(i=i, inp=inp, out=out)
    q = {
        "Korean": "ì…ë ¥: {a} - {h}\nìœ„ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¹ˆë„Â·ê°•ë„Â·Të¥¼ ì˜ˆì¸¡í•˜ê³  ë‹¤ìŒ í˜•ì‹(JSON)ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n{tpl}\nì¶œë ¥:",
        "English": "Input: {a} - {h}\nPredict frequency, intensity, and T then output JSON:\n{tpl}\nOutput:",
        "Chinese": "è¾“å…¥: {a} - {h}\né¢„æµ‹é¢‘ç‡ã€å¼ºåº¦ã€T å¹¶ä»¥ JSON è¾“å‡ºï¼š\n{tpl}\nè¾“å‡º:",
    }[lang]
    prompt += q.format(a=activity, h=hazard, tpl=json_tpl)
    return prompt

def prompt_improvement(examples: pd.DataFrame, activity: str, hazard: str, f: int, i_: int, t: int, lang: str) -> str:
    # Only 2 examples to keep tokens low
    def _json(freq_b, int_b, plan):
        return f"{{\"ê°œì„ ëŒ€ì±…\": \"{plan}\", \"ê°œì„  í›„ ë¹ˆë„\": 1, \"ê°œì„  í›„ ê°•ë„\": 2, \"ê°œì„  í›„ T\": 2, \"T ê°ì†Œìœ¨\": 80.0}}"

    examples_txt = ""
    for k, row in examples.head(2).iterrows():
        examples_txt += (
            f"Example:\nInput: {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']} / {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']} / F={row['ë¹ˆë„']} / I={row['ê°•ë„']} / T={row['T']}\n"
            f"Output(JSON): {_json(row['ë¹ˆë„'], row['ê°•ë„'], 'ì‘ì—… êµ¬ì—­ 3m ì• íœìŠ¤ ì„¤ì¹˜ ë“±')}\n\n"
        )
    body = (
        f"Now provide a **specific, engineeringâ€‘level improvement plan** for the new input and quantify risk reduction.\n"
        f"Input: {activity} / {hazard} / F={f} / I={i_} / T={t}\n"
        f"Return **only valid JSON** with keys: ê°œì„ ëŒ€ì±…, ê°œì„  í›„ ë¹ˆë„, ê°œì„  í›„ ê°•ë„, ê°œì„  í›„ T, T ê°ì†Œìœ¨."
    )
    return examples_txt + body

# -----------------------------------------------------------------------------
# 9. MAIN RUN BLOCK
# -----------------------------------------------------------------------------
if run and user_activity and api_key:

    # 9â€‘1. Load & embed dataset (cached on api_key)
    dataset_df = load_dataset()
    if st.session_state.faiss_index is None:
        with st.spinner("Preparing embeddings ..."):
            idx, emb_arr = build_embeddings(dataset_df, api_key)
            st.session_state.faiss_index = idx
            st.session_state.retriever_df = dataset_df
            st.session_state.embeddings = emb_arr
    else:
        idx = st.session_state.faiss_index
        dataset_df = st.session_state.retriever_df

    # 9â€‘2. Retrieve topâ€‘3 similar rows
    openai.api_key = api_key
    q_emb = openai.Embedding.create(model="text-embedding-3-large", input=[user_activity])["data"][0]["embedding"]
    D, I = idx.search(np.array([q_emb], dtype="float32"), 3)
    retrieved = dataset_df.iloc[I[0]]

    # 9â€‘3. HAZARD prediction
    haz_prompt = prompt_hazard(retrieved[["ì‘ì—…í™œë™ ë° ë‚´ìš©", "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥"]], user_activity, st.session_state.lang)
    hazard = gpt_chat(haz_prompt, api_key, st.session_state.lang, 120)

    # 9â€‘4. RISK numbers
    risk_prompt = prompt_risk(retrieved[["ì‘ì—…í™œë™ ë° ë‚´ìš©", "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥", "ë¹ˆë„", "ê°•ë„", "T"]],
                              user_activity, hazard, st.session_state.lang)
    risk_json = gpt_chat(risk_prompt, api_key, st.session_state.lang, 120)
    match = re.search(r"([1-5]).*?([1-5]).*?(\d+)", risk_json)
    freq = int(match.group(1)) if match else 3
    inten = int(match.group(2)) if match else 3
    t_val = int(match.group(3)) if match else freq * inten
    grade = determine_grade(t_val, st.session_state.lang)

    # 9â€‘5. IMPROVEMENT plan
    imp_prompt = prompt_improvement(retrieved, user_activity, hazard, freq, inten, t_val, st.session_state.lang)
    imp_json_raw = gpt_chat(imp_prompt, api_key, st.session_state.lang, 200)
    try:
        imp_data = json.loads(re.sub("```[a-z]*", "", imp_json_raw))
    except Exception:
        imp_data = {}
    imp_plan = imp_data.get("ê°œì„ ëŒ€ì±…", imp_json_raw)
    imp_freq = imp_data.get("ê°œì„  í›„ ë¹ˆë„", 1)
    imp_inten = imp_data.get("ê°œì„  í›„ ê°•ë„", 2)
    imp_t = imp_data.get("ê°œì„  í›„ T", imp_freq * imp_inten)
    imp_rrr = imp_data.get("T ê°ì†Œìœ¨", round((t_val - imp_t) * 100 / t_val, 2))

    # 9â€‘6. DISPLAY RESULTS ------------------------------------------------------
    st.markdown("## " + TXT["result_header"])

    # risk table fixed width, scrollable rows
    st.write("### AI Risk Assessment")
    assess_df = pd.DataFrame({
        "ì‘ì—…í™œë™": [user_activity],
        "ìœ í•´ìœ„í—˜ìš”ì¸": [hazard],
        "ë¹ˆë„": [freq],
        "ê°•ë„": [inten],
        "T": [t_val],
        TXT["grade"]: [grade],
    })
    st.dataframe(assess_df, use_container_width=True)

    # improvement
    st.write("### " + TXT["improvement_header"])
    imp_df = pd.DataFrame({
        "í•­ëª©": ["ë¹ˆë„", "ê°•ë„", "T"],
        "ê°œì„  ì „": [freq, inten, t_val],
        "ê°œì„  í›„": [imp_freq, imp_inten, imp_t],
    })
    st.dataframe(imp_df, use_container_width=True)
    st.success(f"**RRR:** {imp_rrr}%")
    st.markdown(f"**ê°œì„ ëŒ€ì±…:**\n{imp_plan}")

    # similar cases
    st.write("### " + TXT["similar_cases"])
    st.dataframe(retrieved[["ì‘ì—…í™œë™ ë° ë‚´ìš©", "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥", "T", "ë“±ê¸‰"]], height=180)

    st.session_state.last_result = {
        "assessment": assess_df,
        "improvement": imp_df,
    }
else:
    st.info("â¬…ï¸  ì‚¬ì´ë“œë°”ì— APIÂ Keyì™€ ì‘ì—…í™œë™ì„ ì…ë ¥ í›„ **Run** ì„ ëˆ„ë¥´ì„¸ìš”.")
