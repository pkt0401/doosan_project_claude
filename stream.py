import streamlit as st
import pandas as pd
import numpy as np
import faiss
import openai
import re
import os
import io  # NEW: for Excel download
from PIL import Image
from sklearn.model_selection import train_test_split

# ------------------------------ ê¸°ë³¸ ì„¤ì • ------------------------------

st.set_page_config(
    page_title="Artificial Intelligence Risk Assessment (KOR)",
    page_icon="ğŸ› ï¸",
    layout="wide",
)

# ------------------------------ ìŠ¤íƒ€ì¼ ------------------------------

st.markdown(
    """
<style>
.main-header {font-size: 2.5rem; color: #1E88E5; text-align: center; margin-bottom: 1rem;}
.sub-header {font-size: 1.6rem; color: #0D47A1; margin: 1.5rem 0 1rem;}
.metric-container {background-color: #f0f2f6; border-radius: 10px; padding: 20px; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);}
.result-box {background-color: #f8f9fa; border-radius: 10px; padding: 15px; margin: 10px 0; border-left: 5px solid #4CAF50;}
.similar-case {background-color: #f1f8e9; border-radius: 8px; padding: 12px; margin-bottom: 8px; border-left: 4px solid #689f38;}
</style>
""",
    unsafe_allow_html=True,
)

# ------------------------------ ì„¸ì…˜ ìƒíƒœ ------------------------------

if "index" not in st.session_state:
    st.session_state.index = None
if "retriever_pool_df" not in st.session_state:
    st.session_state.retriever_pool_df = None
if "last_result" not in st.session_state:
    st.session_state.last_result = None

# ------------------------------ ìœ í‹¸ í•¨ìˆ˜ ------------------------------

def determine_grade(value: int) -> str:
    if 16 <= value <= 25:
        return "A"
    elif 10 <= value <= 15:
        return "B"
    elif 5 <= value <= 9:
        return "C"
    elif 3 <= value <= 4:
        return "D"
    elif 1 <= value <= 2:
        return "E"
    return "ì•Œ ìˆ˜ ì—†ìŒ"


def load_data(name: str) -> pd.DataFrame:
    """ì—‘ì…€ì—ì„œ ë°ì´í„°ì…‹ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜í•œë‹¤."""
    try:
        df = pd.read_excel(f"{name}.xlsx")
        if "ì‚­ì œ Del" in df.columns:
            df = df.drop(["ì‚­ì œ Del"], axis=1)
        df = df.iloc[1:]
        df = df.rename(columns={df.columns[4]: "ë¹ˆë„", df.columns[5]: "ê°•ë„"})
        df["T"] = pd.to_numeric(df.iloc[:, 4]) * pd.to_numeric(df.iloc[:, 5])
        df = df.iloc[:, :7]
        df.rename(
            columns={
                "ì‘ì—…í™œë™ ë° ë‚´ìš©\nWork & Contents": "ì‘ì—…í™œë™ ë° ë‚´ìš©",
                "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥\nHazard & Risk": "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥",
            },
            inplace=True,
        )
        df = df.rename(columns={df.columns[6]: "T"})
        df["ë“±ê¸‰"] = df["T"].apply(determine_grade)
        return df
    except Exception:
        # ë°ëª¨ìš© ìƒ˜í”Œ ë°ì´í„°
        data = {
            "ì‘ì—…í™œë™ ë° ë‚´ìš©": ["Shoring Installation", "In and Out of materials"],
            "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥": [
                "Ground collapse",
                "Vehicle overturn",
            ],
            "í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥": ["Injury", "Damage"],
            "ë¹ˆë„": [3, 3],
            "ê°•ë„": [2, 3],
        }
        df = pd.DataFrame(data)
        df["T"] = df["ë¹ˆë„"] * df["ê°•ë„"]
        df["ë“±ê¸‰"] = df["T"].apply(determine_grade)
        return df


def embed_texts(texts, api_key):
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ëª©ë¡ì„ ì„ë² ë”©í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    openai.api_key = api_key
    embeddings = []
    for text in texts:
        try:
            resp = openai.Embedding.create(model="text-embedding-3-large", input=[str(text)])
            embeddings.append(resp["data"][0]["embedding"])
        except Exception:
            embeddings.append([0] * 1536)
    return embeddings


def gpt_chat(prompt, api_key, model="gpt-4o"):
    openai.api_key = api_key
    resp = openai.ChatCompletion.create(model=model, messages=[{"role": "user", "content": prompt}], temperature=0.0, max_tokens=256)
    return resp["choices"][0]["message"]["content"].strip()

# ---- Phase 1 prompt builders (Korean only) ----


def prompt_hazard(examples: pd.DataFrame, activity: str) -> str:
    intro = "ë‹¤ìŒì€ ê±´ì„¤ í˜„ì¥ì˜ ì‘ì—…í™œë™ê³¼ ê·¸ì— ë”°ë¥¸ ìœ í•´ìœ„í—˜ìš”ì¸ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤:\n\n"
    body = "".join(
        [
            f"ì˜ˆì‹œ {i+1}:\nì‘ì—…í™œë™: {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}\nìœ í•´ìœ„í—˜ìš”ì¸: {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}\n\n"
            for i, row in examples.iterrows()
        ]
    )
    query = f"ì´ì œ ë‹¤ìŒ ì‘ì—…í™œë™ì— ëŒ€í•œ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”:\nì‘ì—…í™œë™: {activity}\nìœ í•´ìœ„í—˜ìš”ì¸: "
    return intro + body + query


def prompt_risk(examples: pd.DataFrame, activity: str, hazard: str) -> str:
    tpl_example = "ì˜ˆì‹œ {i}:\nì…ë ¥: {inp}\nì¶œë ¥: {{\"ë¹ˆë„\": {f}, \"ê°•ë„\": {s}, \"T\": {t}}}\n\n"
    body = "".join(
        [
            tpl_example.format(
                i=i + 1,
                inp=f"{row['ì‘ì—…í™œë™ ë° ë‚´ìš©']} - {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}",
                f=int(row["ë¹ˆë„"]),
                s=int(row["ê°•ë„"]),
                t=int(row["T"]),
            )
            for i, row in examples.iterrows()
        ]
    )

    query = (
        f"ì…ë ¥: {activity} - {hazard}\nìœ„ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¹ˆë„ì™€ ê°•ë„ë¥¼ ì˜ˆì¸¡í•˜ì„¸ìš”. ë¹ˆë„ëŠ” 1ì—ì„œ 5 ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤. "
        "ê°•ë„ëŠ” 1ì—ì„œ 5 ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤. TëŠ” ë¹ˆë„ì™€ ê°•ë„ë¥¼ ê³±í•œ ê°’ì…ë‹ˆë‹¤.\në‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
        "{\"ë¹ˆë„\": ìˆ«ì, \"ê°•ë„\": ìˆ«ì, \"T\": ìˆ«ì}\nì¶œë ¥:\n"
    )
    return body + query


def parse_risk(output: str):
    m = re.search(r'{"ë¹ˆë„":\s*([1-5]),\s*"ê°•ë„":\s*([1-5]),\s*"T":\s*(\d+)}', output)
    if not m:
        return None
    f, s, t = map(int, m.groups())
    return f, s, t

# ---- Phase 2 prompt & parsing (Korean) ----


def prompt_improvement(examples: pd.DataFrame, activity: str, hazard: str, freq: int, severity: int, t_val: int) -> str:
    body = ""
    added = 0
    for _, row in examples.iterrows():
        if "ê°œì„ ëŒ€ì±…" in row and pd.notna(row["ê°œì„ ëŒ€ì±…"]):
            imp = row["ê°œì„ ëŒ€ì±…"]
            of, os = int(row["ë¹ˆë„"]), int(row["ê°•ë„"])
            ot = of * os
            body += (
                "Example:\n"
                f"Input (Activity): {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}\n"
                f"Input (Hazard): {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}\n"
                f"Input (Original Frequency): {of}\nInput (Original Intensity): {os}\nInput (Original T): {ot}\n"
                "Output (Improvement Plan and Risk Reduction) in JSON:\n"
                "{\n  \"ê°œì„ ëŒ€ì±…\": \"%s\",\n  \"ê°œì„  í›„ ë¹ˆë„\": 1,\n  \"ê°œì„  í›„ ê°•ë„\": 1,\n  \"ê°œì„  í›„ T\": 1,\n  \"T ê°ì†Œìœ¨\": 90.0\n}\n\n" % imp
            )
            added += 1
            if added >= 2:
                break
    query = (
        "ë‹¤ìŒì€ ìƒˆë¡œìš´ ì…ë ¥ì…ë‹ˆë‹¤:\n"
        f"ì…ë ¥ (ì‘ì—…í™œë™): {activity}\nì…ë ¥ (ìœ í•´ìœ„í—˜ìš”ì¸): {hazard}\nì…ë ¥ (ì›ë˜ ë¹ˆë„): {freq}\nì…ë ¥ (ì›ë˜ ê°•ë„): {severity}\nì…ë ¥ (ì›ë˜ T): {t_val}\n\n"
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ì„ ì œê³µí•˜ì„¸ìš”:\n{\n  \"ê°œì„ ëŒ€ì±…\": \"í•­ëª©ë³„ ê°œì„ ëŒ€ì±… ë¦¬ìŠ¤íŠ¸\",\n  \"ê°œì„  í›„ ë¹ˆë„\": (1..5),\n  \"ê°œì„  í›„ ê°•ë„\": (1..5),\n  \"ê°œì„  í›„ T\": (ìˆ«ì),\n  \"T ê°ì†Œìœ¨\": (í¼ì„¼íŠ¸)\n}\n\nê°œì„ ëŒ€ì±…ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ìµœì†Œ 3ê°œì˜ êµ¬ì²´ì ì¸ ê°œì„  ì¡°ì¹˜ë¥¼ ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ëª©ë¡ìœ¼ë¡œ ì œê³µí•˜ì‹­ì‹œì˜¤. ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤.\nì¶œë ¥:\n"
    )
    return body + query


def parse_improvement(output: str):
    try:
        js = re.search(r'{.*}', output, re.DOTALL)
        if not js:
            return None
        import json
        data = json.loads(js.group())
        keys = ["ê°œì„ ëŒ€ì±…", "ê°œì„  í›„ ë¹ˆë„", "ê°œì„  í›„ ê°•ë„", "ê°œì„  í›„ T", "T ê°ì†Œìœ¨"]
        return {k: data.get(k) for k in keys}
    except Exception:
        return None

# ------------------------------ UI ------------------------------

st.markdown("<div class='main-header'>LLM ê¸°ë°˜ ìœ„í—˜ì„± í‰ê°€ Â· ê°œì„ ëŒ€ì±… ìƒì„± (í†µí•©)</div>", unsafe_allow_html=True)

# 1) API Key & Dataset
api_key = st.text_input("ğŸ”‘ OpenAI API Key", type="password")

datasets = {
    "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)": "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)",
    "Civil (í† ëª©)": "Civil (í† ëª©)",
    "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)": "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)"
}
sel_ds = st.selectbox("ë°ì´í„°ì…‹ ì„ íƒ", list(datasets.keys()))

if st.button("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì¸ë±ìŠ¤ êµ¬ì¶•"):
    if not api_key:
        st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("ë°ì´í„° ë¡œë“œ ì¤‘..."):
            df = load_data(datasets[sel_ds])
            train_df, _ = train_test_split(df, test_size=0.1, random_state=42)
            pool_df = train_df.copy()
            pool_df["content"] = pool_df.apply(lambda r: " ".join(r.values.astype(str)), axis=1)
            texts = pool_df["content"].tolist()[:10]
            embeds = embed_texts(texts, api_key)
            embeds_np = np.array(embeds, dtype="float32")
            idx = faiss.IndexFlatL2(embeds_np.shape[1])
            idx.add(embeds_np)
            st.session_state.index = idx
            st.session_state.retriever_pool_df = pool_df
        st.success("ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")

st.divider()

# 2) User Input -> All results
work = st.text_input("ì‘ì—…í™œë™ ë° ë‚´ìš© ì…ë ¥ í›„ Enter: ")

if st.button("ìœ„í—˜ì„± í‰ê°€ + ê°œì„ ëŒ€ì±… ìƒì„±"):
    if not api_key:
        st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif st.session_state.index is None:
        st.warning("ë¨¼ì € ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì„¸ìš”.")
    elif not work:
        st.warning("ì‘ì—…í™œë™ì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("ëª¨ë“  ê²°ê³¼ ìƒì„± ì¤‘..."):
            # ------- Retrieve examples -------
            q_embed = embed_texts([work], api_key)[0]
            D, I = st.session_state.index.search(np.array([q_embed], dtype="float32"), 3)
            examples = st.session_state.retriever_pool_df.iloc[I[0]].copy()

            # ìœ ì‚¬ ì‚¬ë¡€ í‘œì‹œ (ì¹´ë“œ í˜•ì‹)
            st.markdown("<div class='sub-header'>ìœ ì‚¬ ì‚¬ë¡€</div>", unsafe_allow_html=True)
            for i, row in examples.iterrows():
                st.markdown(
                    f"<div class='similar-case'><b>#{i}</b> ì‘ì—…í™œë™: {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}<br>ìœ í•´ìœ„í—˜ìš”ì¸: {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}<br>ë¹ˆë„: {row['ë¹ˆë„']} ê°•ë„: {row['ê°•ë„']} T: {row['T']} ë“±ê¸‰: {row['ë“±ê¸‰']}</div>",
                    unsafe_allow_html=True,
                )

            # ìœ ì‚¬ ì‚¬ë¡€ í…Œì´ë¸” (NEW)
            st.markdown("##### ìœ ì‚¬ ì‚¬ë¡€ ìƒì„¸ (Table)")
            st.dataframe(examples[[
                "ì‘ì—…í™œë™ ë° ë‚´ìš©", "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥", "ë¹ˆë„", "ê°•ë„", "T", "ë“±ê¸‰", "ê°œì„ ëŒ€ì±…", "ê°œì„  í›„ ë¹ˆë„", "ê°œì„  í›„ ê°•ë„", "ê°œì„  í›„ T", "T ê°ì†Œìœ¨"
            ]])

            # ------- Phase 1: Hazard -------
            h_prompt = prompt_hazard(examples, work)
            hazard = gpt_chat(h_prompt, api_key)

            r_prompt = prompt_risk(examples, work, hazard)
            risk_out = gpt_chat(r_prompt, api_key)
            risk_vals = parse_risk(risk_out)
            if not risk_vals:
                st.error("ë¹ˆë„/ê°•ë„ íŒŒì‹± ì‹¤íŒ¨")
                st.write(risk_out)
                st.stop()
            freq, sev, t_val = risk_vals
            grade = determine_grade(t_val)

            # ------- Phase 2: Improvement -------
            i_prompt = prompt_improvement(examples, work, hazard, freq, sev, t_val)
            imp_out = gpt_chat(i_prompt, api_key)
            imp_parsed = parse_improvement(imp_out)
            if not imp_parsed:
                st.error("ê°œì„ ëŒ€ì±… íŒŒì‹± ì‹¤íŒ¨")
                st.write(imp_out)
                st.stop()

        # ----------------- ê²°ê³¼ í‘œì‹œ -----------------
        st.markdown("<div class='sub-header'>ì˜ˆì¸¡ ê²°ê³¼</div>", unsafe_allow_html=True)
        st.markdown(
            f"<div class='result-box'>ì‘ì—…í™œë™: <b>{work}</b><br>ì˜ˆì¸¡ëœ ìœ í•´ìœ„í—˜ìš”ì¸: <b>{hazard}</b></div>",
            unsafe_allow_html=True,
        )

        st.table(
            pd.DataFrame(
                {
                    "í•­ëª©": ["ë¹ˆë„", "ê°•ë„", "T", "ë“±ê¸‰"],
                    "ê°’": [freq, sev, t_val, grade],
                }
            )
        )

        st.markdown("<div class='sub-header'>ê°œì„ ëŒ€ì±… ë° ìœ„í—˜ë„ ê°œì„ </div>", unsafe_allow_html=True)
        col1, col2 = st.columns([3, 2])
        with col1:
            st.markdown("##### ê°œì„ ëŒ€ì±…")
            st.markdown(imp_parsed["ê°œì„ ëŒ€ì±…"])
        with col2:
            st.markdown("##### ê°œì„  ì „í›„ ë¹„êµ")
            imp_freq = imp_parsed.get("ê°œì„  í›„ ë¹ˆë„", 1)
            imp_sev = imp_parsed.get("ê°œì„  í›„ ê°•ë„", 1)
            imp_t = imp_parsed.get("ê°œì„  í›„ T", imp_freq * imp_sev)
            rrr = imp_parsed.get("T ê°ì†Œìœ¨", (t_val - imp_t) / t_val * 100)
            compare_df = pd.DataFrame(
                {
                    "í•­ëª©": ["ë¹ˆë„", "ê°•ë„", "T", "ë“±ê¸‰"],
                    "ê°œì„  ì „": [freq, sev, t_val, grade],
                    "ê°œì„  í›„": [imp_freq, imp_sev, imp_t, determine_grade(imp_t)],
                }
            )
            st.table(compare_df)
            st.metric("T ê°ì†Œìœ¨", f"{rrr:.2f}%")

        st.progress(imp_t / 25)

        # ----------------- ê²°ê³¼ Excel ë‹¤ìš´ë¡œë“œ (NEW) -----------------
        st.markdown("<div class='sub-header'>ğŸ“Š ê²°ê³¼ ë‹¤ìš´ë¡œë“œ</div>", unsafe_allow_html=True)
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            # ì‹œíŠ¸ 1: ì˜ˆì¸¡ ìš”ì•½
            summary_df = pd.DataFrame({
                "í•­ëª©": ["ì‘ì—…í™œë™", "ì˜ˆìƒ ìœ í•´ìœ„í—˜ìš”ì¸", "ë¹ˆë„", "ê°•ë„", "T", "ë“±ê¸‰", "ê°œì„ ëŒ€ì±…", "ê°œì„  í›„ ë¹ˆë„", "ê°œì„  í›„ ê°•ë„", "ê°œì„  í›„ T", "T ê°ì†Œìœ¨"],
                "ê°’": [work, hazard, freq, sev, t_val, grade, imp_parsed["ê°œì„ ëŒ€ì±…"], imp_freq, imp_sev, imp_t, rrr],
            })
            summary_df.to_csv(writer, index=False, sheet_name="Summary")
            # ì‹œíŠ¸ 2: ìœ ì‚¬ ì‚¬ë¡€
            examples.to_csv(writer, index=False, sheet_name="Similar Cases")
        output.seek(0)


        
        st.download_button(
            label="ğŸ“¥ ê²°ê³¼ Excel ë‹¤ìš´ë¡œë“œ",
            data=output.getvalue(),
            file_name="risk_assessment_result.csv",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

# ------------------------------ ë¡œê³  ------------------------------

st.divider()
cols = st.columns(2)
for img_path, w, col in [("cau.png", 150, cols[0]), ("doosan.png", 180, cols[1])]:
    if os.path.exists(img_path):
        col.image(Image.open(img_path), width=w)
