import streamlit as st
import openai
import numpy as np
import json
import os

# Set page configuration for wide layout and title
st.set_page_config(page_title="Artificial Intelligence Risk Assessment", layout="wide")


st.sidebar.markdown("## ğŸ”‘ OpenAI API Key")
user_api_key = st.sidebar.text_input("Enter your OpenAI API Key", type="password")

# OpenAI í˜¸ì¶œ ì „ API í‚¤ ê²€ì¦
if not user_api_key:
    st.warning("âš ï¸ Please input your OpenAI API Key at left.")
    st.stop()

# Mapping for language selection (display text to code)
lang_map = {
    "ğŸ‡°ğŸ‡· Korean": "ko",
    "ğŸ‡ºğŸ‡¸ English": "en",
    "ğŸ‡¨ğŸ‡³ Chinese": "zh"
}

# Prepare text strings in different languages for UI elements
app_title = {
    "ko": "ì¸ê³µì§€ëŠ¥ ìœ„í—˜ì„± í‰ê°€", 
    "en": "Artificial Intelligence Risk Assessment", 
    "zh": "äººå·¥æ™ºèƒ½é£é™©è¯„ä¼°"
}
input_labels = {
    "category": {"ko": "ê³µì¢…", "en": "Construction Category", "zh": "æ–½å·¥ç±»åˆ«"},
    "activity": {"ko": "ì‘ì—…í™œë™ ë° ë‚´ìš©", "en": "Work Activity & Details", "zh": "å·¥ä½œæ´»åŠ¨åŠå†…å®¹"},
    "submit": {"ko": "ìœ„í—˜ì„± í‰ê°€ ì‹¤í–‰", "en": "Run Risk Assessment", "zh": "æ‰§è¡Œé£é™©è¯„ä¼°"},
    "similar_cases": {"ko": "ìœ ì‚¬ ì‚¬ë¡€", "en": "Similar Cases", "zh": "ç±»ä¼¼æ¡ˆä¾‹"}
}
category_options = {
    "ko": ["ê±´ì¶•", "í† ëª©", "í”ŒëœíŠ¸"],
    "en": ["Building", "Civil", "Plant"],
    "zh": ["å»ºç­‘", "åœŸæœ¨", "å·¥å‚"]
}
placeholder_text = {
    "ko": "ì˜ˆ: 5ë¯¸í„° ë†’ì´ ë¹„ê³„ ì‘ì—… ì¤‘ ìì¬ ì¸ì–‘",
    "en": "e.g., Lifting materials on a 5m high scaffold",
    "zh": "ä¾‹å¦‚: åœ¨5ç±³é«˜çš„è„šæ‰‹æ¶ä¸Šæå‡ææ–™"
}
results_title = {
    "ko": "AI ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼",
    "en": "AI Risk Assessment",
    "zh": "AIé£é™©è¯„ä¼°ç»“æœ"
}
summary_template = {
    "ko": (
        "ì´ ì‘ì—…ì˜ ìœ„í—˜ì„±ì„ í‰ê°€í•œ ê²°ê³¼, **{hazard}**ìœ¼ë¡œ ì¸í•œ ì‚¬ê³  ë°œìƒ ìœ„í—˜ì´ "
        "**{grade} ë“±ê¸‰**ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ë˜í•œ, ìœ ì‚¬í•œ ì¤‘ëŒ€ì¬í•´ ì‚¬ë¡€ê°€ ì´ **{count}ê±´** í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
    ),
    "en": (
        "The risk assessment indicates that the risk of an accident due to **{hazard}** "
        "is at a **{grade}** level. Additionally, a total of **{count}** similar serious accident cases were found."
    ),
    "zh": (
        "é£é™©è¯„ä¼°æ˜¾ç¤ºï¼Œç”±äº**{hazard}**å¯¼è‡´äº‹æ•…å‘ç”Ÿçš„é£é™©ç­‰çº§ä¸º**{grade}çº§**ã€‚"
        "å¦å¤–ï¼Œå…±å‘ç°**{count}**èµ·ç±»ä¼¼çš„é‡å¤§äº‹æ•…æ¡ˆä¾‹ã€‚"
    )
}

# Set up OpenAI API key (from secrets or environment)
if "OPENAI_API_KEY" in st.secrets:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
elif os.getenv("OPENAI_API_KEY"):
    openai.api_key = os.getenv("OPENAI_API_KEY")
else:
    st.warning("OpenAI API key is not set. Please add it to Streamlit secrets or environment variable.")

# Layout: Title on left, language selector on right
col1, col2 = st.columns([9, 1])
with col1:
    # Display the app title in the selected language (synced with language choice)
    selected_lang = st.session_state.get("selected_lang", "ğŸ‡°ğŸ‡· Korean")
    st.title(app_title[lang_map[selected_lang]])
with col2:
    # Language selector at top-right with flag icons
    selected_lang = st.selectbox("Language", list(lang_map.keys()), index=list(lang_map.keys()).index(selected_lang))
    # Remember choice in session state for persistence
    st.session_state["selected_lang"] = selected_lang

# Determine language code from selection (e.g., "ko", "en", "zh")
lang_code = lang_map[selected_lang]

# Columns for input (left) and output (right)
col_input, col_output = st.columns([1, 3])
with col_input:
    # Input Form for category and work activity
    with st.form("input_form"):
        # Category selection (ê³µì¢…)
        st.markdown(f"**{input_labels['category'][lang_code]}**")  # Show the label in bold
        category = st.selectbox(
            "", 
            options=category_options[lang_code], 
            index=0, 
            key="category_select"
        )
        # Work activity description text area
        description = st.text_area(
            input_labels["activity"][lang_code], 
            value="", 
            placeholder=placeholder_text[lang_code], 
            key="activity_input"
        )
        # Submit button triggers the risk assessment
        submitted = st.form_submit_button(input_labels["submit"][lang_code])

# When the form is submitted, perform the AI analysis (Phase 1 & 2)
if submitted:
    # Combine category and description for AI prompt context
    task_description = (
        f"{input_labels['category'][lang_code]}: {category}\n"
        f"{input_labels['activity'][lang_code]}: {description}"
    )
    # **Phase 1** â€“ Hazard Prediction and Risk Assessment
    try:
        if lang_code == "ko":
            # Korean prompt for hazard identification
            system_msg = (
                "ë‹¹ì‹ ì€ ê±´ì„¤ ì•ˆì „ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì‘ì—…ì— ëŒ€í•´ ë°œìƒ ê°€ëŠ¥í•œ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ì‹ë³„í•˜ê³ , "
                "ê° ìš”ì¸ì˜ ìœ„í—˜ ìˆ˜ì¤€ì„ Aë¶€í„° Eê¹Œì§€ ë“±ê¸‰ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”. (A: ê°€ì¥ ë†’ì€ ìœ„í—˜, E: ê°€ì¥ ë‚®ì€ ìœ„í—˜) "
                "ê°œì„  ëŒ€ì±…ì€ ì´ ë‹¨ê³„ì—ì„œ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”."
            )
            user_msg = (
                task_description + 
                "\nìœ„ì˜ ì‘ì—…ì— ëŒ€í•œ ìœ í•´ìœ„í—˜ìš”ì¸ê³¼ ê°œì„  ì „ ìœ„í—˜ë“±ê¸‰(A~E)ì„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë³´ì—¬ì£¼ì„¸ìš”. "
                "í‚¤ëŠ” 'hazard'ì™€ 'risk_grade'ë¡œ í•´ì£¼ì„¸ìš”."
            )
        elif lang_code == "zh":
            # Chinese prompt for hazard identification
            system_msg = (
                "ä½ æ˜¯ä¸€ä½å»ºç­‘æ–½å·¥å®‰å…¨ä¸“å®¶AIã€‚è¯·è¯†åˆ«ç»™å®šå·¥ä½œä¸­çš„æ½œåœ¨å±é™©å› ç´ ï¼Œå¹¶è¯„ä¼°æ¯ä¸ªå±é™©å› ç´ åœ¨"
                "æ²¡æœ‰ä»»ä½•æ”¹è¿›æªæ–½æ—¶çš„é£é™©ç­‰çº§ï¼ˆAè‡³Eï¼ŒAä¸ºæœ€é«˜é£é™©ï¼ŒEä¸ºæœ€ä½é£é™©ï¼‰ã€‚åœ¨æ­¤é˜¶æ®µä¸éœ€è¦æä¾›æ”¹è¿›æªæ–½ã€‚"
            )
            user_msg = (
                task_description + 
                "\nè¯·ä»¥JSONæ ¼å¼è¿”å›è¿™äº›å±é™©å› ç´ åŠå…¶é£é™©ç­‰çº§ã€‚JSONæ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ åº”åŒ…å« 'hazard' å’Œ 'risk_grade' å­—æ®µã€‚"
                "åªè¾“å‡ºJSONï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜ã€‚"
            )
        else:
            # English prompt for hazard identification
            system_msg = (
                "You are a construction safety expert AI. Identify potential hazards for the given task and assess the "
                "risk level of each hazard before any improvements. Risk levels should be graded from A (highest risk) to "
                "E (lowest risk). Do not provide any improvement measures yet."
            )
            user_msg = (
                task_description + 
                "\nList the hazards and their risk grade (A-E) in JSON format as an array of objects with keys 'hazard' and 'risk_grade'. "
                "Provide only the JSON output with no extra text."
            )
        # Call OpenAI API for hazard identification
        response1 = openai.ChatCompletion.create(
            model="gpt-4o",  # or "gpt-4" if available
            api_key=user_api_key,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ]
        )
        hazards_content = response1.choices[0].message.content.strip()
        # Remove any Markdown formatting (like ```json``` wrappers) from the response
        if hazards_content.startswith("```"):
            hazards_content = hazards_content.strip("```").strip()
            if hazards_content.lower().startswith("json"):
                hazards_content = hazards_content[len("json"):].strip()
        # Parse the JSON string to Python data
        hazards_data = json.loads(hazards_content)
    except Exception as e:
        st.error("Failed to retrieve hazard information. Please try again.")
        st.stop()
    # Validate that we got a list of hazards
    if not isinstance(hazards_data, list):
        st.error("Unexpected hazards format from AI. Please try again.")
        st.stop()

    # **Phase 2** â€“ Generate Improvement Measures for each identified hazard
    try:
        if lang_code == "ko":
            # Prepare hazard list text for Korean prompt
            hazard_list_text = "\n".join([
                f"- {item['hazard']} (ë“±ê¸‰: {item['risk_grade']})" 
                for item in hazards_data
            ])
            system_msg2 = (
                "ë‹¹ì‹ ì€ ê±´ì„¤ ì•ˆì „ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì´ì œ ê° ìœ„í—˜ìš”ì¸ì— ëŒ€í•œ ê°œì„  ëŒ€ì±…ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ê³  "
                "ê°œì„  í›„ ìœ„í—˜ë“±ê¸‰ì„ í‰ê°€í•˜ì„¸ìš”."
            )
            user_msg2 = (
                f"ì‹ë³„ëœ ìœ„í—˜ìš”ì¸ ëª©ë¡:\n{hazard_list_text}\n"
                "ê° ìœ„í—˜ìš”ì¸ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ê°œì„ ëŒ€ì±…ì„ ì œì•ˆí•˜ê³ , ê°œì„  ì¡°ì¹˜ ì‹œí–‰ í›„ì˜ ìƒˆë¡œìš´ ìœ„í—˜ë“±ê¸‰(A~E)ì„ ì•Œë ¤ì£¼ì„¸ìš”. "
                "ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”. ê° ìš”ì†ŒëŠ” 'hazard', 'risk_grade_before', 'improvement', 'risk_grade_after' í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."
            )
        elif lang_code == "zh":
            # Prepare hazard list text for Chinese prompt
            hazard_list_text = "\n".join([
                f"- {item['hazard']} (ç­‰çº§: {item['risk_grade']})" 
                for item in hazards_data
            ])
            system_msg2 = "ä½ æ˜¯ä¸€ä½å»ºç­‘å®‰å…¨ä¸“å®¶AIã€‚è¯·ä¸ºæ¯ä¸ªå±é™©å› ç´ æä¾›æ”¹è¿›æªæ–½ã€‚"
            user_msg2 = (
                f"å·²è¯†åˆ«çš„å±é™©å› ç´ åˆ—è¡¨:\n{hazard_list_text}\n"
                "è¯·é’ˆå¯¹ä¸Šè¿°æ¯ä¸ªå±é™©å› ç´ æä¾›å…·ä½“å¯è¡Œçš„æ”¹è¿›æªæ–½ï¼Œå¹¶ç»™å‡ºå®æ–½æ”¹è¿›åçš„æ–°çš„é£é™©ç­‰çº§ï¼ˆAè‡³Eï¼‰ã€‚"
                "è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'hazard', 'risk_grade_before', 'improvement', 'risk_grade_after' å­—æ®µã€‚"
            )
        else:
            # Prepare hazard list text for English prompt
            hazard_list_text = "\n".join([
                f"- {item['hazard']} (Grade: {item['risk_grade']})" 
                for item in hazards_data
            ])
            system_msg2 = (
                "You are a construction safety expert AI. Provide improvement measures for each identified hazard."
            )
            user_msg2 = (
                f"Identified hazards:\n{hazard_list_text}\n"
                "For each hazard listed above, suggest a specific and actionable improvement measure to mitigate it, "
                "and provide the new risk grade (A-E) after implementing the improvement. "
                "Respond in JSON format as an array of objects, each with 'hazard', 'risk_grade_before', 'improvement', 'risk_grade_after'."
            )
        # Call OpenAI API for improvement measures
        response2 = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # or "gpt-4" for potentially better output
            messages=[
                {"role": "system", "content": system_msg2},
                {"role": "user", "content": user_msg2}
            ]
        )
        improvement_content = response2.choices[0].message.content.strip()
        # Strip any Markdown formatting from the response
        if improvement_content.startswith("```"):
            improvement_content = improvement_content.strip("```").strip()
            if improvement_content.lower().startswith("json"):
                improvement_content = improvement_content[len("json"):].strip()
        improvements_data = json.loads(improvement_content)
    except Exception as e:
        st.error("Failed to retrieve improvement measures. Please try again.")
        st.stop()
    # Validate that we got a list of improvements
    if not isinstance(improvements_data, list):
        st.error("Unexpected improvements format from AI. Please try again.")
        st.stop()

    # **Summary & Results Display**

    # Determine the highest-risk hazard identified (for summary sentence)
    risk_rank = {"A": 5, "B": 4, "C": 3, "D": 2, "E": 1}  # higher number = higher risk
    highest_hazard = max(hazards_data, key=lambda x: risk_rank.get(x.get("risk_grade", "E"), 1)) if hazards_data else None
    hazard_name = highest_hazard.get("hazard", "") if highest_hazard else ""
    risk_grade = highest_hazard.get("risk_grade", "") if highest_hazard else ""

    # Retrieve similar past cases using cosine similarity on embeddings (retrieved_docs)
    # Note: In a real app, pre-compute and store embeddings for a large case database for efficiency.
    example_cases = {
        "ko": [
            "ê±´ì„¤ í˜„ì¥ì—ì„œ ì‘ì—…ìê°€ ë¹„ê³„ì—ì„œ ì¶”ë½í•˜ì—¬ ë¶€ìƒ",
            "êµ´ì°© ì‘ì—… ì¤‘ í† ì‚¬ê°€ ë¶•ê´´ë¨",
            "í¬ë ˆì¸ ì‘ì—…ì—ì„œ ë¬¼ì²´ê°€ ë‚™í•˜í•¨"
        ],
        "en": [
            "Worker fell from scaffolding at a construction site",
            "Soil collapsed during an excavation work",
            "An object fell during a crane operation"
        ],
        "zh": [
            "å»ºç­‘å·¥åœ°çš„å·¥äººä»è„šæ‰‹æ¶ä¸Šå è½å—ä¼¤",
            "æŒ–æ˜ä½œä¸šä¸­åœŸæ–¹åå¡Œ",
            "èµ·é‡æœºä½œä¸šæ—¶ç‰©ä½“å è½"
        ]
    }
    case_texts = example_cases.get(lang_code, [])
    similar_cases = []
    similar_count = 0
    if case_texts:
        try:
            # Create embeddings for the user input description and example cases
            embed_input = [description] + case_texts
            embed_response = openai.Embedding.create(model="text-embedding-ada-002", input=embed_input)
            embeddings = [item["embedding"] for item in embed_response["data"]]
            query_vec = embeddings[0]
            case_vecs = embeddings[1:]
            # Compute cosine similarity between input and each case
            query_norm = np.linalg.norm(query_vec)
            similarities = []
            for vec in case_vecs:
                sim_val = np.dot(query_vec, vec) / (query_norm * np.linalg.norm(vec))
                similarities.append(sim_val)
            # Filter cases with similarity >= 0.70
            for sim_val, text in sorted(zip(similarities, case_texts), key=lambda x: x[0], reverse=True):
                if sim_val >= 0.70:
                    similar_cases.append((text, sim_val))
            similar_count = len(similar_cases)
            # (If no case meets the threshold, similar_cases will remain empty and count = 0)
        except Exception as e:
            # If embedding fails, proceed without retrieved cases
            similar_cases = []
            similar_count = 0

    # Display the results in the output column
    with col_output:
        # Section title (localized)
        st.subheader(results_title[lang_code])
        # Summary sentence with main hazard and risk grade
        summary_text = summary_template[lang_code].format(hazard=hazard_name, grade=risk_grade, count=similar_count)
        st.markdown(summary_text)
        # Table of hazards, improvements, and risk grades
        table_rows = []
        for item in improvements_data:
            hazard_factor = item.get("hazard", "")
            before_grade = item.get("risk_grade_before", "")
            improvement_measure = item.get("improvement", "")
            after_grade = item.get("risk_grade_after", "")
            table_rows.append({
                # Column headers are localized based on selected language
                "ìœ í•´ìœ„í—˜ìš”ì¸" if lang_code == "ko" else ("å±é™©å› ç´ " if lang_code == "zh" else "Hazard Factor"): hazard_factor,
                "ê°œì„ ì „ ë“±ê¸‰" if lang_code == "ko" else ("æ”¹è¿›å‰ç­‰çº§" if lang_code == "zh" else "Risk Grade (Before)") : before_grade,
                "ê°œì„ ëŒ€ì±…" if lang_code == "ko" else ("æ”¹è¿›æªæ–½" if lang_code == "zh" else "Improvement Measure"): improvement_measure,
                "ê°œì„ í›„ ë“±ê¸‰" if lang_code == "ko" else ("æ”¹è¿›åç­‰çº§" if lang_code == "zh" else "Risk Grade (After)") : after_grade
            })
        st.table(table_rows)
        # List of similar past cases (if any found above similarity threshold)
        if similar_cases:
            st.subheader(input_labels["similar_cases"][lang_code])
            for text, sim_val in similar_cases:
                # Display each case with its cosine similarity score
                st.write(f"- ({sim_val:.2f}) {text}")
# If form not submitted yet, show an instructional message in the output area
else:
    with col_output:
        st.info("â¤ Please enter the work activity details on the left, then click **Run Risk Assessment** to see results.")
