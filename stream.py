import streamlit as st
import pandas as pd
import numpy as np
import faiss
import openai
import re
import os
from sklearn.model_selection import train_test_split

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LLM í™œìš© ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ë° ì‚¬ê³  ì˜ˆì¸¡",
    page_icon="ğŸ› ï¸",
    layout="wide"
)

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #0D47A1;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .info-text {
        font-size: 1rem;
        color: #424242;
        margin-bottom: 1rem;
    }
    .highlight {
        background-color: #e3f2fd;
        padding: 5px;
        border-radius: 5px;
    }
    .result-box {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 15px;
        margin-top: 10px;
        margin-bottom: 10px;
        border-left: 5px solid #4CAF50;
    }
    .phase-badge {
        background-color: #4CAF50;
        color: white;
        padding: 5px 10px;
        border-radius: 15px;
        font-size: 0.8rem;
        margin-right: 10px;
    }
    .process-step {
        display: flex;
        align-items: center;
        margin-bottom: 8px;
    }
    .process-arrow {
        color: #4CAF50;
        font-size: 20px;
        margin: 0 10px;
    }
    .process-container {
        display: flex;
        flex-direction: column;
        padding: 20px;
        background-color: #f9f9f9;
        border-radius: 10px;
        margin: 20px 0;
    }
    .step-container {
        display: flex;
        align-items: center;
        margin-bottom: 10px;
    }
    .step-number {
        margin-right: 10px;
        font-weight: bold;
    }
    .step-content {
        flex-grow: 1;
    }
    .arrow-down {
        text-align: center;
        margin: 5px 0;
        color: #4CAF50;
    }
</style>
""", unsafe_allow_html=True)

# í—¤ë” í‘œì‹œ
st.markdown('<div class="main-header">LLM í™œìš© ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ë° ì‚¬ê³  ì˜ˆì¸¡</div>', unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "index" not in st.session_state:
    st.session_state.index = None
if "embeddings" not in st.session_state:
    st.session_state.embeddings = None
if "retriever_pool_df" not in st.session_state:
    st.session_state.retriever_pool_df = None

# íƒ­ ì„¤ì • - ë°ì´í„° íƒìƒ‰ íƒ­ ì œê±°
tabs = st.tabs(["ì‹œìŠ¤í…œ ê°œìš”", "ìœ„í—˜ì„± í‰ê°€ (Phase 1)", "ê°œì„ ëŒ€ì±… ìƒì„± (Phase 2)"])

# ------------------ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ------------------

# ë¹ˆë„*ê°•ë„ ê²°ê³¼ Tì— ë”°ë¥¸ ë“±ê¸‰ ê²°ì • í•¨ìˆ˜
def determine_grade(value):
    """ë¹ˆë„*ê°•ë„ ê²°ê³¼ Tì— ë”°ë¥¸ ë“±ê¸‰ ê²°ì • í•¨ìˆ˜."""
    if 16 <= value <= 25:
        return 'A'
    elif 10 <= value <= 15:
        return 'B'
    elif 5 <= value <= 9:
        return 'C'
    elif 3 <= value <= 4:
        return 'D'
    elif 1 <= value <= 2:
        return 'E'
    else:
        return 'ì•Œ ìˆ˜ ì—†ìŒ'

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_data(selected_dataset_name):
    """ì„ íƒëœ ì´ë¦„ì— ëŒ€ì‘í•˜ëŠ” Excel ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°."""
    try:
        # ì‹¤ì œ Excel íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        df = pd.read_excel(f"{selected_dataset_name}.xlsx")

        # ì „ì²˜ë¦¬
        if 'ì‚­ì œ Del' in df.columns:
            df = df.drop(['ì‚­ì œ Del'], axis=1)
        df = df.iloc[1:]
        df = df.rename(columns={df.columns[4]: 'ë¹ˆë„'})
        df = df.rename(columns={df.columns[5]: 'ê°•ë„'})

        df['T'] = pd.to_numeric(df.iloc[:, 4]) * pd.to_numeric(df.iloc[:, 5])
        df = df.iloc[:, :7]
        df.rename(
            columns={
                'ì‘ì—…í™œë™ ë° ë‚´ìš©\nWork & Contents': 'ì‘ì—…í™œë™ ë° ë‚´ìš©',
                'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥\nHazard & Risk': 'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥',
                'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥\nDamage & Effect': 'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥'
            },
            inplace=True
        )
        df = df.rename(columns={df.columns[6]: 'T'})
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)

        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.write(f"ì‹œë„í•œ íŒŒì¼ ê²½ë¡œ: {selected_dataset_name}")
        
        # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„í•œ ë”ë¯¸ ë°ì´í„° ìƒì„± (ë°ëª¨ìš©)
        st.warning("Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” í•´ë‹¹ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        data = {
            "ì‘ì—…í™œë™ ë° ë‚´ìš©": ["Shoring Installation", "In and Out of materials", "Transport / Delivery", "Survey and Inspection"],
            "ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥": ["Fall and collision due to unstable ground", "Overturning of transport vehicle", 
                                 "Collision between transport vehicle", "Personnel fall while inspecting"],
            "í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥": ["Injury", "Equipment damage", "Collision injury", "Fall injury"],
            "ë¹ˆë„": [3, 3, 3, 2],
            "ê°•ë„": [2, 3, 5, 3]
        }
        
        df = pd.DataFrame(data)
        df['T'] = df['ë¹ˆë„'] * df['ê°•ë„']
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)
        
        return df

# OpenAI ì„ë² ë”© APIë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
def embed_texts_with_openai(texts, model="text-embedding-3-large", api_key=None):
    """OpenAI ì„ë² ë”© APIë¡œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©."""
    if api_key:
        openai.api_key = api_key
    
    embeddings = []
    progress_bar = st.progress(0)
    total = len(texts)

    for idx, text in enumerate(texts):
        try:
            text = str(text).replace("\n", " ")
            response = openai.Embedding.create(model=model, input=[text])
            embedding = response["data"][0]["embedding"]
            embeddings.append(embedding)
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            embeddings.append([0]*1536)
        
        progress_bar.progress((idx + 1) / total)
    
    return embeddings

# GPT ëª¨ë¸ì„ í†µí•´ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±
def generate_with_gpt(prompt, api_key=None, model="gpt-4o"):
    """GPT ëª¨ë¸ë¡œë¶€í„° ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜."""
    if api_key:
        openai.api_key = api_key
        
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": "ìœ„í—˜ì„± í‰ê°€ ë° ê°œì„ ëŒ€ì±… ìƒì„±ì„ ë•ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=250
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        st.error(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ----- Phase 1: ìœ„í—˜ì„± í‰ê°€ ê´€ë ¨ í•¨ìˆ˜ -----

# ê²€ìƒ‰ëœ ë¬¸ì„œë¡œ GPT í”„ë¡¬í”„íŠ¸ ìƒì„± (Phase 1)
def construct_prompt_phase1(retrieved_docs, query_text):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ë¡œë¶€í„° ì˜ˆì‹œë¥¼ êµ¬ì„±í•´ GPT í”„ë¡¬í”„íŠ¸ ìƒì„±."""
    retrieved_examples = []
    for _, doc in retrieved_docs.iterrows():
        try:
            example_input = f"{doc['ì‘ì—…í™œë™ ë° ë‚´ìš©']} {doc['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}"
            frequency = int(doc['ë¹ˆë„'])
            intensity = int(doc['ê°•ë„'])
            T_value = frequency * intensity
            example_output = f'{{"ë¹ˆë„": {frequency}, "ê°•ë„": {intensity}, "T": {T_value}}}'
            retrieved_examples.append((example_input, example_output))
        except:
            continue
    
    prompt = ""
    for i, (example_input, example_output) in enumerate(retrieved_examples, 1):
        prompt += f"ì˜ˆì‹œ {i}:\nì…ë ¥: {example_input}\nì¶œë ¥: {example_output}\n\n"
    
    prompt += (
        f"ì…ë ¥: {query_text}\n"
        "ìœ„ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¹ˆë„ì™€ ê°•ë„ë¥¼ ì˜ˆì¸¡í•˜ì„¸ìš”. "
        "ë¹ˆë„ëŠ” 1ì—ì„œ 5 ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤. "
        "ê°•ë„ëŠ” 1ì—ì„œ 5 ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤. "
        "TëŠ” ë¹ˆë„ì™€ ê°•ë„ë¥¼ ê³±í•œ ê°’ì…ë‹ˆë‹¤.\n"
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
        '{"ë¹ˆë„": ìˆ«ì, "ê°•ë„": ìˆ«ì, "T": ìˆ«ì}\n'
        "ì¶œë ¥:\n"
    )
    return prompt

# GPT ì¶œë ¥ íŒŒì‹± (Phase 1)
def parse_gpt_output_phase1(gpt_output):
    """GPT ì¶œë ¥ì—ì„œ {ë¹ˆë„, ê°•ë„, T}ë¥¼ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ."""
    json_pattern = r'\{"ë¹ˆë„":\s*([1-5]),\s*"ê°•ë„":\s*([1-5]),\s*"T":\s*([0-9]+)\}'
    match = re.search(json_pattern, gpt_output)
    if match:
        pred_frequency = int(match.group(1))
        pred_intensity = int(match.group(2))
        pred_T = int(match.group(3))
        return pred_frequency, pred_intensity, pred_T
    else:
        return None

# ----- Phase 2: ê°œì„ ëŒ€ì±… ìƒì„± ê´€ë ¨ í•¨ìˆ˜ -----

# ìœ„í—˜ ê°ì†Œìœ¨(RRR) ê³„ì‚° í•¨ìˆ˜
def compute_rrr(T_before, T_after):
    """ìœ„í—˜ ê°ì†Œìœ¨(Risk Reduction Rate) ê³„ì‚°"""
    if T_before == 0:
        return 0.0
    return ((T_before - T_after) / T_before) * 100.0

# ê°œì„ ëŒ€ì±… ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Phase 2)
def construct_prompt_phase2(retrieved_docs, activity_text, hazard_text, freq, intensity, T, target_language="Korean"):
    """
    ê°œì„ ëŒ€ì±… ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    """
    # ì˜ˆì‹œ ì„¹ì…˜ êµ¬ì„±
    example_section = ""
    examples_added = 0
    
    for _, row in retrieved_docs.iterrows():
        try:
            # Phase2 ë°ì´í„°ì…‹ì— ìˆëŠ” ê°œì„ ëŒ€ì±… í•„ë“œ ì‚¬ìš© ì‹œë„
            # ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª… ì‹œë„
            improvement_plan = ""
            for field in ['ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ', 'ê°œì„ ëŒ€ì±…', 'ê°œì„ ë°©ì•ˆ']:
                if field in row and pd.notna(row[field]):
                    improvement_plan = row[field]
                    break
            
            if not improvement_plan:
                continue  # ê°œì„ ëŒ€ì±…ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                
            original_freq = int(row['ë¹ˆë„']) if 'ë¹ˆë„' in row else 3
            original_intensity = int(row['ê°•ë„']) if 'ê°•ë„' in row else 3
            original_T = original_freq * original_intensity
                
            # ê°œì„  í›„ ë°ì´í„° ì‹œë„
            improved_freq = 1
            improved_intensity = 1
            improved_T = 1
            
            for field_pattern in [('ê°œì„  í›„ ë¹ˆë„', 'ê°œì„  í›„ ê°•ë„', 'ê°œì„  í›„ T'), ('ê°œì„ ë¹ˆë„', 'ê°œì„ ê°•ë„', 'ê°œì„ T')]:
                if all(field in row for field in field_pattern):
                    improved_freq = int(row[field_pattern[0]])
                    improved_intensity = int(row[field_pattern[1]])
                    improved_T = int(row[field_pattern[2]])
                    break
            
            example_section += (
                "Example:\n"
                f"Input (Activity): {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}\n"
                f"Input (Hazard): {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}\n"
                f"Input (Original Frequency): {original_freq}\n"
                f"Input (Original Intensity): {original_intensity}\n"
                f"Input (Original T): {original_T}\n"
                "Output (Improvement Plan and Risk Reduction) in JSON:\n"
                "{\n"
                f"  \"ê°œì„ ëŒ€ì±…\": \"{improvement_plan}\",\n"
                f"  \"ê°œì„  í›„ ë¹ˆë„\": {improved_freq},\n"
                f"  \"ê°œì„  í›„ ê°•ë„\": {improved_intensity},\n"
                f"  \"ê°œì„  í›„ T\": {improved_T},\n"
                f"  \"T ê°ì†Œìœ¨\": {compute_rrr(original_T, improved_T):.2f}\n"
                "}\n\n"
            )
            
            examples_added += 1
            if examples_added >= 3:  # ìµœëŒ€ 3ê°œ ì˜ˆì‹œë§Œ ì‚¬ìš©
                break
                
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ ì˜ˆì‹œ ê±´ë„ˆë›°ê¸°
            continue
    
    # ì˜ˆì‹œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì˜ˆì‹œ ì¶”ê°€
    if examples_added == 0:
        example_section = """
Example:
Input (Activity): Excavation and backfilling
Input (Hazard): Collapse of excavation wall due to improper sloping
Input (Original Frequency): 3
Input (Original Intensity): 4
Input (Original T): 12
Output (Improvement Plan and Risk Reduction) in JSON:
{
  "ê°œì„ ëŒ€ì±…": "1) í† ì–‘ ë¶„ë¥˜ì— ë”°ë¥¸ ì ì ˆí•œ ê²½ì‚¬ ìœ ì§€ 2) êµ´ì°© ë²½ë©´ ë³´ê°• 3) ì •ê¸°ì ì¸ ì§€ë°˜ ìƒíƒœ ê²€ì‚¬ ì‹¤ì‹œ",
  "ê°œì„  í›„ ë¹ˆë„": 1,
  "ê°œì„  í›„ ê°•ë„": 2,
  "ê°œì„  í›„ T": 2,
  "T ê°ì†Œìœ¨": 83.33
}

Example:
Input (Activity): Lifting operation
Input (Hazard): Material fall due to improper rigging
Input (Original Frequency): 2
Input (Original Intensity): 5
Input (Original T): 10
Output (Improvement Plan and Risk Reduction) in JSON:
{
  "ê°œì„ ëŒ€ì±…": "1) ë¦¬ê¹… ì „ë¬¸ê°€ ì‘ì—… ì°¸ì—¬ 2) ë¦¬ê¹… ì¥ë¹„ ì‚¬ì „ ì ê²€ 3) ì•ˆì „ êµ¬ì—­ ì„¤ì • ë° ì ‘ê·¼ í†µì œ",
  "ê°œì„  í›„ ë¹ˆë„": 1,
  "ê°œì„  í›„ ê°•ë„": 2,
  "ê°œì„  í›„ T": 2,
  "T ê°ì†Œìœ¨": 80.00
}
"""
    
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = (
        f"{example_section}"
        "Now here is a new input:\n"
        f"Input (Activity): {activity_text}\n"
        f"Input (Hazard): {hazard_text}\n"
        f"Input (Original Frequency): {freq}\n"
        f"Input (Original Intensity): {intensity}\n"
        f"Input (Original T): {T}\n\n"
        "Please provide the output in JSON format with these keys:\n"
        "{\n"
        "  \"ê°œì„ ëŒ€ì±…\": \"í•­ëª©ë³„ ê°œì„ ëŒ€ì±… ë¦¬ìŠ¤íŠ¸\", \n"
        "  \"ê°œì„  í›„ ë¹ˆë„\": (an integer in [1..5]),\n"
        "  \"ê°œì„  í›„ ê°•ë„\": (an integer in [1..5]),\n"
        "  \"ê°œì„  í›„ T\": (Improved Frequency * Improved Severity),\n"
        "  \"T ê°ì†Œìœ¨\": (percentage of risk reduction)\n"
        "}\n\n"
        f"Please write the improvement measures (ê°œì„ ëŒ€ì±…) in {target_language}.\n"
        f"Provide at least 3 specific improvement measures as a numbered list.\n"
        "Make sure to return only valid JSON.\n"
        "Output:\n"
    )
    
    return prompt

# GPT ì‘ë‹µ íŒŒì‹± (Phase 2)
def parse_gpt_output_phase2(gpt_output):
    """GPT ì‘ë‹µì—ì„œ JSON ë°ì´í„°ë¥¼ ì¶”ì¶œ"""
    try:
        # JSON ë¸”ë¡ì´ ìˆëŠ” ê²½ìš° ì¶”ì¶œ ì‹œë„
        pattern = re.compile(r"```json(.*?)```", re.DOTALL)
        match = pattern.search(gpt_output)

        if match:
            json_str = match.group(1).strip()
        else:
            # JSON ë¸”ë¡ í‘œì‹œê°€ ì—†ëŠ” ê²½ìš° ì›ë¬¸ì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
            json_str = gpt_output.replace("```", "").strip()

        import json
        result = json.loads(json_str)
        return result
    except Exception as e:
        st.error(f"JSON íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.write("ì›ë³¸ GPT ì‘ë‹µ:", gpt_output)
        return None

# ------------------ ë°ì´í„°ì…‹ ë° ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ ------------------

# ë°ì´í„°ì…‹ ì˜µì…˜
dataset_options = {
    "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)": "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)",
    "Civil (í† ëª©)": "Civil (í† ëª©)",
    "Marine (í† ëª©)": "Marine (í† ëª©)",
    "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)": "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)",
    "SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)": "SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)"
}

# ----- ì‹œìŠ¤í…œ ê°œìš” íƒ­ -----
with tabs[0]:
    st.markdown('<div class="sub-header">LLM ê¸°ë°˜ ìœ„í—˜ì„±í‰ê°€ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.markdown("""
        <div class="info-text">
        LLM(Large Language Model)ì„ í™œìš©í•œ ìœ„í—˜ì„±í‰ê°€ ìë™í™” ì‹œìŠ¤í…œì€ ê±´ì„¤ í˜„ì¥ì˜ ì•ˆì „ ê´€ë¦¬ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤:
        
        1. <span class="highlight">ì‘ì—… ë‚´ìš© ì…ë ¥ ì‹œ ìƒì„±í˜• AIë¥¼ í†µí•œ 'ìœ í•´ìœ„í—˜ìš”ì¸' ë° 'ìœ„í—˜ ë“±ê¸‰' ìë™ ìƒì„±</span> <span class="phase-badge">Phase 1</span>
        2. <span class="highlight">ìœ„í—˜ë„ ê°ì†Œë¥¼ ìœ„í•œ ê°œì„ ëŒ€ì±… ìë™ ìƒì„± ë° ê°ì†Œìœ¨ ì˜ˆì¸¡</span> <span class="phase-badge">Phase 2</span>
        3. AIëŠ” ê±´ì„¤í˜„ì¥ì˜ ê¸°ì¡´ ìœ„í—˜ì„±í‰ê°€ë¥¼ ê³µì •ë³„ë¡œ êµ¬ë¶„í•˜ê³ , í•´ë‹¹ ìœ í•´ìœ„í—˜ìš”ì¸ì„ í•™ìŠµ
        4. ìë™ ìƒì„± ê¸°ìˆ  ê°œë°œ ì™„ë£Œ í›„ ìœ„í—˜ë„ ê¸°ë°˜ ì‚¬ê³ ìœ„í—˜ì„±ê³¼ ì´ë¯¸ì§€ ë¶„ì„ì„ í†µí•œ ì‚¬ê³ ì˜ˆì¸¡ (ê³„íš)
        
        ì´ ì‹œìŠ¤í…œì€ PIMS ë° ì•ˆì „ì§€í‚´ì´ ë“± EHS í”Œë«í¼ì— AI ê¸°ìˆ  íƒ‘ì¬ë¥¼ í†µí•´ í†µí•© ì‚¬ê³  ì˜ˆì¸¡ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ë°œì „ ì˜ˆì •ì…ë‹ˆë‹¤.
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        # AI ìœ„í—˜ì„±í‰ê°€ í”„ë¡œì„¸ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨ - ìˆ˜ì •ëœ ë²„ì „
        st.markdown('<div style="text-align: center; margin-bottom: 10px;"><b>AI ìœ„í—˜ì„±í‰ê°€ í”„ë¡œì„¸ìŠ¤</b></div>', unsafe_allow_html=True)
        
        # í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„ ë° í•´ë‹¹ Phase ì§€ì •
        steps = ["ì‘ì—…ë‚´ìš© ì…ë ¥", "AI ìœ„í—˜ë¶„ì„", "ìœ í•´ìš”ì¸ ì‹ë³„", "ìœ„í—˜ë“±ê¸‰ ì‚°ì •", "ê°œì„ ëŒ€ì±… ìë™ìƒì„±", "ì•ˆì „ì¡°ì¹˜ ì ìš©"]
        phases = ["Phase 1", "Phase 1", "Phase 1", "Phase 1", "Phase 2", "Phase 2"]
        
        # í”„ë¡œì„¸ìŠ¤ íë¦„ì„ ìˆ˜ì§ ë°©í–¥ìœ¼ë¡œ í‘œí˜„
        st.markdown('<div class="process-container">', unsafe_allow_html=True)
        
        for i, (step, phase) in enumerate(zip(steps, phases)):
            st.markdown(
                f'<div class="step-container">'
                f'<div class="step-number">{i+1}.</div>'
                f'<div class="step-content">{step} <span class="phase-badge">{phase}</span></div>'
                f'</div>',
                unsafe_allow_html=True
            )
            
            # ë§ˆì§€ë§‰ ë‹¨ê³„ê°€ ì•„ë‹ˆë©´ í™”ì‚´í‘œ ì¶”ê°€
            if i < len(steps) - 1:
                st.markdown('<div class="arrow-down">â†“</div>', unsafe_allow_html=True)
                
        st.markdown('</div>', unsafe_allow_html=True)
    
    # ì‹œìŠ¤í…œ íŠ¹ì§•
    st.markdown('<div class="sub-header">ì‹œìŠ¤í…œ íŠ¹ì§• ë° êµ¬ì„±ìš”ì†Œ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### Phase 1: ìœ„í—˜ì„± í‰ê°€ ìë™í™”
        - ê³µì •ë³„ ì‘ì—…í™œë™ì— ë”°ë¥¸ ìœ„í—˜ì„±í‰ê°€ ë°ì´í„° í•™ìŠµ
        - ì‘ì—…í™œë™ ì…ë ¥ ì‹œ ìœ í•´ìœ„í—˜ìš”ì¸ ë° ìœ„í—˜ë„ ìë™ ì˜ˆì¸¡
        - ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ ìœ„í—˜ë„(ë¹ˆë„, ê°•ë„, T) ì¸¡ì •
        - Excel ê¸°ë°˜ ê³µì •ë³„ ìœ„í—˜ì„±í‰ê°€ ë°ì´í„° ìë™ ë¶„ì„
        - ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ë° ìœ„í—˜ë“±ê¸‰(A-E) ìë™ ì‚°ì •
        """)
    
    with col2:
        st.markdown("""
        #### Phase 2: ê°œì„ ëŒ€ì±… ìë™ ìƒì„±
        - ìœ„í—˜ìš”ì†Œë³„ ë§ì¶¤í˜• ê°œì„ ëŒ€ì±… ìë™ ìƒì„±
        - ë‹¤êµ­ì–´(í•œ/ì˜/ì¤‘) ê°œì„ ëŒ€ì±… ìƒì„± ì§€ì›
        - ê°œì„  ì „í›„ ìœ„í—˜ë„(T) ìë™ ë¹„êµ ë¶„ì„
        - ìœ„í—˜ ê°ì†Œìœ¨(RRR) ì •ëŸ‰ì  ì‚°ì¶œ
        - ê³µì¢…/ê³µì •ë³„ ìµœì  ê°œì„ ëŒ€ì±… ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
        - ë‘ì‚° ê±´ì„¤í˜„ì¥ í†µí•© AI ì•ˆì „ê´€ë¦¬ ì‹œìŠ¤í…œ ì—°ê³„
        """)

# ----- Phase 1: ìœ„í—˜ì„± í‰ê°€ íƒ­ -----
with tabs[1]:
    st.markdown('<div class="sub-header">ìœ„í—˜ì„± í‰ê°€ ìë™í™” (Phase 1)</div>', unsafe_allow_html=True)
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="api_key_phase1")
    
    # ë°ì´í„°ì…‹ ì„ íƒ
    selected_dataset_name = st.selectbox(
        "ë°ì´í„°ì…‹ ì„ íƒ",
        options=list(dataset_options.keys()),
        key="dataset_selector_phase1"
    )
    
    # ì¸ë±ìŠ¤ êµ¬ì„± ì„¹ì…˜
    st.markdown("### 1. ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„±")
    
    if st.button("ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„±", key="load_data_phase1"):
        if not api_key:
            st.warning("ê³„ì†í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì¸ë±ìŠ¤ë¥¼ êµ¬ì„±í•˜ëŠ” ì¤‘...'):
                # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
                df = load_data(dataset_options[selected_dataset_name])
                
                if df is not None:
                    # Train/Test ë¶„í• 
                    train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)
                    
                    # ë¦¬íŠ¸ë¦¬ë²„ í’€ êµ¬ì„±
                    retriever_pool_df = train_df.copy()
                    retriever_pool_df['content'] = retriever_pool_df.apply(
                        lambda row: ' '.join(row.values.astype(str)), axis=1
                    )
                    texts = retriever_pool_df['content'].tolist()
                    
                    # ì„ë² ë”© ìƒì„± (ë°ëª¨ì—ì„œëŠ” ì ì€ ìˆ˜ë§Œ ì²˜ë¦¬, ì‹¤ì œë¡œëŠ” ì „ì²´ ì²˜ë¦¬)
                    max_texts = min(len(texts), 10)  # ë°ëª¨ì—ì„œëŠ” ìµœëŒ€ 10ê°œë§Œ ì²˜ë¦¬
                    st.info(f"ë°ëª¨ ëª©ì ìœ¼ë¡œ {max_texts}ê°œì˜ í…ìŠ¤íŠ¸ë§Œ ì„ë² ë”©í•©ë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì „ì²´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                    
                    openai.api_key = api_key
                    embeddings = embed_texts_with_openai(texts[:max_texts], api_key=api_key)
                    
                    # FAISS ì¸ë±ìŠ¤ êµ¬ì„±
                    embeddings_array = np.array(embeddings, dtype='float32')
                    dimension = embeddings_array.shape[1]
                    faiss_index = faiss.IndexFlatL2(dimension)
                    faiss_index.add(embeddings_array)
                    
                    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    st.session_state.index = faiss_index
                    st.session_state.embeddings = embeddings_array
                    st.session_state.retriever_pool_df = retriever_pool_df.iloc[:max_texts]  # ì„ë² ë”©ëœ ë¶€ë¶„ë§Œ ì €ì¥
                    
                    st.success(f"ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„± ì™„ë£Œ! (ì´ {max_texts}ê°œ í•­ëª© ì²˜ë¦¬)")
                    st.session_state.test_df = test_df
    
    # ì‚¬ìš©ì ì…ë ¥ ì˜ˆì¸¡ ì„¹ì…˜
    st.markdown("### 2. ìœ„í—˜ì„± í‰ê°€ ì˜ˆì¸¡")
    
    if st.session_state.index is None:
        st.warning("ë¨¼ì € [ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„±] ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    else:
        with st.form("user_input_form"):
            user_work = st.text_input("ì‘ì—…í™œë™:", key="form_user_work")
            user_risk = st.text_input("ìœ í•´ìœ„í—˜ìš”ì¸:", key="form_user_risk")
            submitted = st.form_submit_button("ìœ„í—˜ì„± í‰ê°€ ì˜ˆì¸¡í•˜ê¸°")
            
        if submitted:
            if not user_work or not user_risk:
                st.warning("ì‘ì—…í™œë™ê³¼ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                query_text = f"{user_work} {user_risk}"
                
                with st.spinner("ìœ„í—˜ì„±ì„ í‰ê°€í•˜ëŠ” ì¤‘..."):
                    # ì¿¼ë¦¬ ì„ë² ë”©
                    query_embedding = embed_texts_with_openai([query_text], api_key=api_key)[0]
                    query_embedding_array = np.array([query_embedding], dtype='float32')
                    
                    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
                    k_similar = min(3, len(st.session_state.retriever_pool_df))
                    distances, indices = st.session_state.index.search(query_embedding_array, k_similar)
                    retrieved_docs = st.session_state.retriever_pool_df.iloc[indices[0]]
                    
                    # GPT í”„ë¡¬í”„íŠ¸ ìƒì„± & í˜¸ì¶œ
                    prompt = construct_prompt_phase1(retrieved_docs, query_text)
                    generated_output = generate_with_gpt(prompt, api_key=api_key)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown(f"**ì‚¬ìš©ì ì…ë ¥ ì‘ì—…í™œë™:** {user_work}")
                    st.markdown(f"**ì‚¬ìš©ì ì…ë ¥ ìœ í•´ìœ„í—˜ìš”ì¸:** {user_risk}")
                    
                    parse_result = parse_gpt_output_phase1(generated_output)
                    if parse_result is not None:
                        f_val, i_val, t_val = parse_result
                        grade = determine_grade(t_val)
                        
                        # ê²°ê³¼ë¥¼ í‘œë¡œ í‘œì‹œ
                        result_df = pd.DataFrame({
                            'í•­ëª©': ['ë¹ˆë„', 'ê°•ë„', 'T ê°’', 'ìœ„í—˜ë“±ê¸‰'],
                            'ê°’': [f_val, i_val, t_val, grade]
                        })
                        
                        st.markdown('<div class="result-box">', unsafe_allow_html=True)
                        st.markdown("#### ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼")
                        st.table(result_df)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥ (Phase 2ì—ì„œ ì‚¬ìš©)
                        st.session_state.last_assessment = {
                            'activity': user_work,
                            'hazard': user_risk,
                            'frequency': f_val,
                            'intensity': i_val,
                            'T': t_val,
                            'grade': grade
                        }
                    else:
                        st.error("ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.write(f"GPT ì›ë¬¸ ì‘ë‹µ: {generated_output}")

# ----- Phase 2: ê°œì„ ëŒ€ì±… ìƒì„± íƒ­ -----
with tabs[2]:
    st.markdown('<div class="sub-header">ê°œì„ ëŒ€ì±… ìë™ ìƒì„± (Phase 2)</div>', unsafe_allow_html=True)
    
    # API í‚¤ ì…ë ¥
    api_key_phase2 = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="api_key_phase2")
    
    # ê°œì„ ëŒ€ì±… ì–¸ì–´ ì„ íƒ
    target_language = st.selectbox(
        "ê°œì„ ëŒ€ì±… ì–¸ì–´ ì„ íƒ:",
        options=["Korean", "English", "Chinese"],
        index=0,
        key="target_language"
    )
    
    # ì…ë ¥ ë°©ì‹ ì„ íƒ (Phase 1 ê²°ê³¼ ì‚¬ìš© ë˜ëŠ” ì§ì ‘ ì…ë ¥)
    input_method = st.radio(
        "ì…ë ¥ ë°©ì‹ ì„ íƒ:",
        options=["Phase 1 í‰ê°€ ê²°ê³¼ ì‚¬ìš©", "ì§ì ‘ ì…ë ¥"],
        index=0,
        key="input_method"
    )
    
    if input_method == "Phase 1 í‰ê°€ ê²°ê³¼ ì‚¬ìš©":
        # Phase 1 ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        if hasattr(st.session_state, 'last_assessment'):
            last_assessment = st.session_state.last_assessment
            
            st.markdown("### Phase 1 í‰ê°€ ê²°ê³¼")
            st.markdown(f"**ì‘ì—…í™œë™:** {last_assessment['activity']}")
            st.markdown(f"**ìœ í•´ìœ„í—˜ìš”ì¸:** {last_assessment['hazard']}")
            st.markdown(f"**ìœ„í—˜ë„:** ë¹ˆë„ {last_assessment['frequency']}, ê°•ë„ {last_assessment['intensity']}, Tê°’ {last_assessment['T']} (ë“±ê¸‰ {last_assessment['grade']})")
            
            activity_text = last_assessment['activity']
            hazard_text = last_assessment['hazard']
            frequency = last_assessment['frequency']
            intensity = last_assessment['intensity']
            T_value = last_assessment['T']
            
        else:
            st.warning("ë¨¼ì € Phase 1ì—ì„œ ìœ„í—˜ì„± í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
            activity_text = hazard_text = None
            frequency = intensity = T_value = None
    else:
        # ì§ì ‘ ì…ë ¥í•˜ëŠ” ê²½ìš°
        col1, col2 = st.columns(2)
        
        with col1:
            activity_text = st.text_input("ì‘ì—…í™œë™:", key="direct_activity")
            hazard_text = st.text_input("ìœ í•´ìœ„í—˜ìš”ì¸:", key="direct_hazard")
        
        with col2:
            frequency = st.number_input("ë¹ˆë„ (1-5):", min_value=1, max_value=5, value=3, key="direct_freq")
            intensity = st.number_input("ê°•ë„ (1-5):", min_value=1, max_value=5, value=3, key="direct_intensity")
            T_value = frequency * intensity
            st.markdown(f"**Tê°’:** {T_value} (ë“±ê¸‰: {determine_grade(T_value)})")
    
    # ê°œì„ ëŒ€ì±… ìƒì„± ì„¹ì…˜
    if st.button("ê°œì„ ëŒ€ì±… ìƒì„±", key="generate_improvement") and activity_text and hazard_text and frequency and intensity and T_value:
        if not api_key_phase2:
            st.warning("ê³„ì†í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ê°œì„ ëŒ€ì±…ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                # ë¦¬íŠ¸ë¦¬ë²„ í’€ê³¼ ì¸ë±ìŠ¤ í™•ì¸
                if st.session_state.retriever_pool_df is None or st.session_state.index is None:
                    st.warning("Phase 1ì—ì„œ ë°ì´í„° ë¡œë“œ ë° ì¸ë±ìŠ¤ êµ¬ì„±ì„ ì™„ë£Œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì˜ˆì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    # ê¸°ë³¸ ê³µí†µ ë°ì´í„°ì…‹ ë¡œë“œ
                    df = load_data("Civil (í† ëª©)")
                    retriever_pool_df = df.sample(min(5, len(df)))  # ìµœëŒ€ 5ê°œ ìƒ˜í”Œ
                    
                    # ìœ ì‚¬ ë¬¸ì„œëŠ” ëœë¤ ìƒ˜í”Œë§
                    retrieved_docs = retriever_pool_df.sample(min(3, len(retriever_pool_df)))
                else:
                    # Phase 1ì—ì„œ êµ¬ì„±ëœ ë¦¬íŠ¸ë¦¬ë²„ í’€ ë° ì¸ë±ìŠ¤ ì‚¬ìš©
                    retriever_pool_df = st.session_state.retriever_pool_df
                    
                    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ì‹¤ì œ ë˜ëŠ” ëª¨ì˜)
                    k_similar = min(3, len(retriever_pool_df))
                    query_text = f"{activity_text} {hazard_text}"
                    query_embedding = embed_texts_with_openai([query_text], api_key=api_key_phase2)[0]
                    query_embedding_array = np.array([query_embedding], dtype='float32')
                    distances, indices = st.session_state.index.search(query_embedding_array, k_similar)
                    retrieved_docs = retriever_pool_df.iloc[indices[0]]
                
                # ê°œì„ ëŒ€ì±… ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                prompt = construct_prompt_phase2(
                    retrieved_docs, 
                    activity_text, 
                    hazard_text, 
                    frequency, 
                    intensity, 
                    T_value, 
                    target_language
                )
                
                # GPT í˜¸ì¶œ
                generated_output = generate_with_gpt(prompt, api_key=api_key_phase2)
                
                # ê²°ê³¼ íŒŒì‹±
                parsed_result = parse_gpt_output_phase2(generated_output)
                
                if parsed_result:
                    # ê²°ê³¼ í‘œì‹œ
                    improvement_plan = parsed_result.get("ê°œì„ ëŒ€ì±…", "")
                    improved_freq = parsed_result.get("ê°œì„  í›„ ë¹ˆë„", 1)
                    improved_intensity = parsed_result.get("ê°œì„  í›„ ê°•ë„", 1)
                    improved_T = parsed_result.get("ê°œì„  í›„ T", improved_freq * improved_intensity)
                    rrr = parsed_result.get("T ê°ì†Œìœ¨", compute_rrr(T_value, improved_T))
                    
                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.markdown("#### ê°œì„ ëŒ€ì±… ìƒì„± ê²°ê³¼")
                    
                    col1, col2 = st.columns([3, 2])
                    
                    with col1:
                        st.markdown("##### ê°œì„ ëŒ€ì±…")
                        st.markdown(improvement_plan)
                    
                    with col2:
                        st.markdown("##### ìœ„í—˜ë„ ê°œì„  ê²°ê³¼")
                        
                        # ê°œì„  ì „í›„ ìœ„í—˜ë„ ë¹„êµí‘œ
                        comparison_df = pd.DataFrame({
                            'í•­ëª©': ['ë¹ˆë„', 'ê°•ë„', 'Tê°’', 'ìœ„í—˜ë“±ê¸‰'],
                            'ê°œì„  ì „': [frequency, intensity, T_value, determine_grade(T_value)],
                            'ê°œì„  í›„': [improved_freq, improved_intensity, improved_T, determine_grade(improved_T)]
                        })
                        st.table(comparison_df)
                        
                        # ìœ„í—˜ ê°ì†Œìœ¨ í‘œì‹œ
                        st.metric(
                            label="ìœ„í—˜ ê°ì†Œìœ¨ (RRR)",
                            value=f"{rrr:.2f}%"
                        )
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # ìœ„í—˜ë„ ê·¸ë˜í”„ë¡œ í‘œí˜„ (ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œê°í™”)
                    st.markdown("#### ìœ„í—˜ë„(Tê°’) ë³€í™”")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ê°œì„  ì „ Tê°’:**")
                        st.progress(T_value / 25)  # 25ëŠ” ìµœëŒ€ Tê°’
                    
                    with col2:
                        st.markdown("**ê°œì„  í›„ Tê°’:**")
                        st.progress(improved_T / 25)
                else:
                    st.error("ê°œì„ ëŒ€ì±… ìƒì„± ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.write("GPT ì›ë¬¸ ì‘ë‹µ:", generated_output)

# í‘¸í„°
st.markdown("""
<div style="text-align: center; margin-top: 30px; padding: 10px; background-color: #f0f2f6; border-radius: 10px;">
    <p>Â© 2023-2025 ë‘ì‚°ê±´ì„¤ LLM í™œìš© ìœ„í—˜ì„±í‰ê°€ ìë™ ìƒì„± ì‹œìŠ¤í…œ</p>
    <p style="font-size: 0.8rem;">ìµœì‹  ì—…ë°ì´íŠ¸: 2025ë…„ 4ì›” 8ì¼</p>
</div>
""", unsafe_allow_html=True)
