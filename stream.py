import streamlit as st
import pandas as pd
import numpy as np
import faiss
import torch
import openai
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import re
import os
import json
from tqdm import tqdm

# ----- ì „ì—­ ë³€ìˆ˜ (ë°ì´í„°ì…‹ ì„ íƒ ì˜µì…˜) -----
dataset_options = {
    "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)": "SWRO ê±´ì¶•ê³µì • (ê±´ì¶•)",
    "Civil (í† ëª©)": "Civil (í† ëª©)",
    "Marine (í† ëª©)": "Marine (í† ëª©)",
    "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)": "SWRO ê¸°ê³„ê³µì‚¬ (í”ŒëœíŠ¸)",
    "SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)": "SWRO ì „ê¸°ì‘ì—…í‘œì¤€ (í”ŒëœíŠ¸)"
}

# ì–¸ì–´ ì„ íƒ ì˜µì…˜ (Phase 2ì—ì„œ ì‚¬ìš©)
language_options = ["Korean", "Chinese", "English"]

def determine_grade(value):
    """ë¹ˆë„*ê°•ë„ ê²°ê³¼ Tì— ë”°ë¥¸ ë“±ê¸‰ ê²°ì • í•¨ìˆ˜."""
    if 16 <= value <= 25:
        return 'A'
    elif 10 <= value <= 15:
        return 'B'
    elif 5 <= value <= 9:
        return 'C'
    elif 3 <= value <= 4:
        return 'D'
    elif 1 <= value <= 2:
        return 'E'
    else:
        return 'ì•Œ ìˆ˜ ì—†ìŒ'

def load_data(selected_dataset_name):
    """ì„ íƒëœ ì´ë¦„ì— ëŒ€ì‘í•˜ëŠ” Excel ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°."""
    try:
        df = pd.read_excel(f"{selected_dataset_name}.xlsx")

        # ì „ì²˜ë¦¬
        if 'ì‚­ì œ Del' in df.columns:
            df = df.drop(['ì‚­ì œ Del'], axis=1)
        df = df.iloc[1:]
        df = df.rename(columns={df.columns[4]: 'ë¹ˆë„'})
        df = df.rename(columns={df.columns[5]: 'ê°•ë„'})

        df['T'] = pd.to_numeric(df.iloc[:, 4]) * pd.to_numeric(df.iloc[:, 5])
        df = df.iloc[:, :7]
        df.rename(
            columns={
                'ì‘ì—…í™œë™ ë° ë‚´ìš©\nWork & Contents': 'ì‘ì—…í™œë™ ë° ë‚´ìš©',
                'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥\nHazard & Risk': 'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥',
                'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥\nDamage & Effect': 'í”¼í•´í˜•íƒœ ë° í™˜ê²½ì˜í–¥'
            },
            inplace=True
        )
        df = df.rename(columns={df.columns[6]: 'T'})
        df['ë“±ê¸‰'] = df['T'].apply(determine_grade)

        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.write(f"ì‹œë„í•œ íŒŒì¼ ê²½ë¡œ: {selected_dataset_name}")
        return None

def generate_with_gpt4(prompt):
    """GPT-4 ëª¨ë¸ë¡œë¶€í„° ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜."""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ìœ„í—˜ì„± í‰ê°€ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=50
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        st.error(f"GPT-4 API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def embed_texts_with_openai(texts, model="text-embedding-3-large"):
    """OpenAI ì„ë² ë”© APIë¡œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©."""
    embeddings = []
    progress_bar = st.progress(0)
    total = len(texts)

    for idx, text in enumerate(tqdm(texts, desc="ì„ë² ë”© ì§„í–‰ ì¤‘", unit="ê°œ")):
        try:
            text = text.replace("\n", " ")
            response = openai.Embedding.create(model=model, input=[text])
            embedding = response["data"][0]["embedding"]
            embeddings.append(embedding)
        except Exception as e:
            st.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            embeddings.append([0]*1536)
        
        progress_bar.progress((idx + 1) / total)
    
    return embeddings

def construct_prompt(retrieved_docs, query_text):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ë¡œë¶€í„° ì˜ˆì‹œë¥¼ êµ¬ì„±í•´ GPT í”„ë¡¬í”„íŠ¸ ìƒì„±."""
    retrieved_examples = []
    for _, doc in retrieved_docs.iterrows():
        content_parts = doc['content'].split()
        example_input = ' '.join(content_parts[:-6])
        frequency = int(content_parts[-4])
        intensity = int(content_parts[-3])
        T_value = frequency * intensity
        example_output = f'{{"ë¹ˆë„": {frequency}, "ê°•ë„": {intensity}, "T": {T_value}}}'
        retrieved_examples.append((example_input, example_output))
    
    prompt = ""
    for i, (example_input, example_output) in enumerate(retrieved_examples, 1):
        prompt += f"ì˜ˆì‹œ {i}:\nì…ë ¥: {example_input}\nì¶œë ¥: {example_output}\n\n"
    
    prompt += (
        f"ì…ë ¥: {query_text}\n"
        "ìœ„ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¹ˆë„ì™€ ê°•ë„ë¥¼ ì˜ˆì¸¡í•˜ì„¸ìš”. "
        "ë¹ˆë„ëŠ” 1ì—ì„œ 5 ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤. "
        "ê°•ë„ëŠ” 1ì—ì„œ 5 ì‚¬ì´ì˜ ì •ìˆ˜ì…ë‹ˆë‹¤. "
        "TëŠ” ë¹ˆë„ì™€ ê°•ë„ë¥¼ ê³±í•œ ê°’ì…ë‹ˆë‹¤.\n"
        "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n"
        '{"ë¹ˆë„": ìˆ«ì, "ê°•ë„": ìˆ«ì, "T": ìˆ«ì}\n'
        "ì¶œë ¥:\n"
    )
    return prompt

def parse_gpt_output(gpt_output):
    """
    GPT ì¶œë ¥ì—ì„œ {ë¹ˆë„, ê°•ë„, T}ë¥¼ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ.
    ë§¤ì¹­ ì„±ê³µ ì‹œ (ë¹ˆë„, ê°•ë„, T)ë¥¼ ë¦¬í„´, ì‹¤íŒ¨ ì‹œ None ë¦¬í„´.
    """
    json_pattern = r'\{"ë¹ˆë„":\s*([1-5]),\s*"ê°•ë„":\s*([1-5]),\s*"T":\s*([0-9]+)\}'
    match = re.search(json_pattern, gpt_output)
    if match:
        pred_frequency = int(match.group(1))
        pred_intensity = int(match.group(2))
        pred_T = int(match.group(3))
        return pred_frequency, pred_intensity, pred_T
    else:
        return None

# ----- Phase 2 ê´€ë ¨ ì¶”ê°€ í•¨ìˆ˜ë“¤ -----

def get_openai_embedding(text, model_name="text-embedding-3-small"):
    """OpenAI APIë¥¼ ì‚¬ìš©í•´ ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    response = openai.Embedding.create(
        model=model_name,
        input=[text]
    )
    vector = response["data"][0]["embedding"]
    return np.array(vector, dtype=np.float32)

def call_gpt(prompt, model_name="gpt-4o-mini"):
    """GPT ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ë°›ì•„ì˜µë‹ˆë‹¤."""
    try:
        response = openai.ChatCompletion.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant specializing in safety enhancements to effectively minimize risk (T)."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.0,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"GPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

def parse_gpt_response(raw_text):
    """GPT ì‘ë‹µì—ì„œ JSON í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    pattern = re.compile(r"```json(.*?)```", re.DOTALL)
    match = pattern.search(raw_text)

    if match:
        json_str = match.group(1).strip()
    else:
        json_str = raw_text.replace("```", "").replace("```json", "").strip()

    try:
        return json.loads(json_str)
    except:
        try:
            # JSON ë¬¸ë²• ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆì–´ ë” ê´€ëŒ€í•œ ë°©ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„
            import ast
            # ë”°ì˜´í‘œ í†µì¼ (ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ)
            fixed_str = json_str.replace("'", "\"")
            # ë”°ì˜´í‘œê°€ ëˆ„ë½ëœ í‚¤ë¥¼ ìˆ˜ì •
            fixed_str = re.sub(r'(\s*)(\w+)(\s*):(\s*)', r'\1"\2"\3:\4', fixed_str)
            return json.loads(fixed_str)
        except:
            st.warning("GPT ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return None

def predict_improvement(activity_text, hazard_text, top_k=3, embedding_model="text-embedding-3-small", target_language="Korean"):
    """
    ì‘ì—…í™œë™ê³¼ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œì„ ëŒ€ì±…ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    
    Args:
        activity_text: ì‘ì—…í™œë™ í…ìŠ¤íŠ¸
        hazard_text: ìœ í•´ìœ„í—˜ìš”ì¸ í…ìŠ¤íŠ¸
        top_k: ê²€ìƒ‰í•  ìœ ì‚¬ ì˜ˆì‹œ ê°œìˆ˜
        embedding_model: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ì´ë¦„
        target_language: ê²°ê³¼ë¥¼ ì¶œë ¥í•  ì–¸ì–´ (Korean, Chinese, English)
    
    Returns:
        GPT ëª¨ë¸ì´ ìƒì„±í•œ ì›ì‹œ ì‘ë‹µ ë¬¸ìì—´
    """
    # retriever_pool_dfê°€ ì„¸ì…˜ ìƒíƒœì— ìˆëŠ”ì§€ í™•ì¸
    if "retriever_pool_df" not in st.session_state:
        st.error("ë°ì´í„°ì…‹ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì„ë² ë”© ì‚¬ì „ ê³„ì‚°ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None
        
    # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì„ë² ë”©
    query_text = f"{activity_text} {hazard_text}"
    query_embedding = get_openai_embedding(query_text, model_name=embedding_model)

    # FAISS ê²€ìƒ‰ (ì¸ë±ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸)
    if "phase2_index" not in st.session_state:
        st.error("FAISS ì¸ë±ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì„ë² ë”© ì‚¬ì „ ê³„ì‚°ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None
        
    distances, idxs = st.session_state.phase2_index.search(query_embedding.reshape(1, -1), top_k)
    retrieved_docs = st.session_state.retriever_pool_df.iloc[idxs[0]]

    # ì˜ˆì‹œ ì„¹ì…˜ êµ¬ì„±
    example_section = ""
    for _, row in retrieved_docs.iterrows():
        example_section += (
            "Example:\n"
            f"Input (Activity, Hazard): {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']} / {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}\n"
            "Output (Improvement Plan, Improved Freq/Sev/T) in JSON:\n"
            "{"
            f"\"ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ\": \"{row.get('ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ', 'NA')}\", "
            f"\"ê°œì„  í›„ ë¹ˆë„\": {row.get('ê°œì„  í›„ ë¹ˆë„', 1)}, "
            f"\"ê°œì„  í›„ ê°•ë„\": {row.get('ê°œì„  í›„ ê°•ë„', 1)}, "
            f"\"ê°œì„  í›„ T\": {row.get('ê°œì„  í›„ T', 1)}"
            "}\n\n"
        )

    # ìµœì¢… í”„ë¡¬í”„íŠ¸
    prompt = (
        f"{example_section}"
        "Now here is a new input:\n"
        f"ì‘ì—…í™œë™ ë° ë‚´ìš©: {activity_text}\n"
        f"ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥: {hazard_text}\n\n"
        "Please provide the output in JSON format with these keys:\n"
        "{\n"
        "  \"ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ\": \"...\", \n"
        "  \"ê°œì„  í›„ ë¹ˆë„\": (an integer in [1..5]),\n"
        "  \"ê°œì„  í›„ ê°•ë„\": (an integer in [1..5]),\n"
        "  \"ê°œì„  í›„ T\": (Improved Frequency * Improved Severity)\n"
        "}\n\n"
        f"Please write the content (ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ) in {target_language}.\n"
        "Make sure to return only valid JSON.\n"
        "Output:\n"
    )

    # GPT ëª¨ë¸ í˜¸ì¶œ
    gpt_raw = call_gpt(prompt)
    return gpt_raw

def compute_rrr(T_before, T_after):
    """Risk Reduction Rate(RRR) aê³„ì‚° í•¨ìˆ˜"""
    if T_before == 0:
        return 0.0
    return ((T_before - T_after) / T_before) * 100.0

def main():
    st.set_page_config(
        page_title="ìœ„í—˜ì„± í‰ê°€ ì‹œìŠ¤í…œ",
        page_icon="ğŸ—ï¸",
        layout="wide"
    )

    # ----- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” -----
    if "index" not in st.session_state:
        st.session_state.index = None
    if "embeddings" not in st.session_state:
        st.session_state.embeddings = None
    if "phase2_index" not in st.session_state:
        st.session_state.phase2_index = None
    if "retriever_pool_df" not in st.session_state:
        st.session_state.retriever_pool_df = None

    # ë©”ì¸ íƒ€ì´í‹€
    st.title("ìƒì„±í˜• AI ê¸°ë°˜ ìœ„í—˜ì„± í‰ê°€ ì‹œìŠ¤í…œ")

    # ë°ì´í„°ì…‹ ì„ íƒ
    selected_dataset_name = st.selectbox(
        "ë°ì´í„°ì…‹ ì„ íƒ",
        options=list(dataset_options.keys()),
        key="dataset_selector"
    )
    st.write(f"ì„ íƒëœ ë°ì´í„°ì…‹: {selected_dataset_name}")

    # ë¡œê³  í‘œì‹œ
    col1, col2 = st.columns(2)
    with col1:
        try:
            st.image("cau.png", width=200)
        except Exception:
            st.error("ì¤‘ì•™ëŒ€í•™êµ ë¡œê³  ë¡œë”© ì‹¤íŒ¨")
    with col2:
        try:
            st.image("doosan.png", width=200)
        except Exception:
            st.error("ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹° ë¡œê³  ë¡œë”© ì‹¤íŒ¨")

    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        type="password",
        help="API í‚¤ëŠ” ì•ˆì „í•˜ê²Œ ë³´ê´€ë©ë‹ˆë‹¤."
    )
    if not api_key:
        st.warning("ê³„ì†í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        return
    openai.api_key = api_key

    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
        df = load_data(dataset_options[selected_dataset_name])
    if df is None:
        return

    # train/test ë¶„í• 
    train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)
    test_df = test_df[['ì‘ì—…í™œë™ ë° ë‚´ìš©', 'ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥', 'ë¹ˆë„', 'ê°•ë„', 'T']]

    # Retriever Pool êµ¬ì„±
    retriever_pool_df = train_df.copy()
    retriever_pool_df['content'] = retriever_pool_df.apply(
        lambda row: ' '.join(row.values.astype(str)), axis=1
    )
    texts = retriever_pool_df['content'].tolist()

    # ----- íƒ­ êµ¬ë¶„ -----
    tabs = st.tabs(["ì„ë² ë”© ì‚¬ì „ ê³„ì‚°", "ì‚¬ìš©ì ì…ë ¥ ì˜ˆì¸¡", "ìƒ˜í”Œ ì˜ˆì¸¡", "ê°œì„ ëŒ€ì±… ìƒì„±"])

    # íƒ­ 1) ì„ë² ë”© ì‚¬ì „ ê³„ì‚°
    with tabs[0]:
        st.subheader("ì„ë² ë”© ê³„ì‚° / ì¸ë±ìŠ¤ êµ¬ì„±")

        if st.session_state.index is not None:
            st.success("ì´ë¯¸ ì„ë² ë”© ê³„ì‚° ë° ì¸ë±ìŠ¤ êµ¬ì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            if st.button("ì„ë² ë”© ì‚¬ì „ ê³„ì‚°", key="run_embedding"):
                with st.spinner('ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ì¤‘...'):
                    # Phase 1 ì„ë² ë”© ë° ì¸ë±ìŠ¤
                    embeddings = embed_texts_with_openai(texts)
                    if not embeddings:
                        st.error("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                        return
                    st.session_state.embeddings = np.array(embeddings, dtype='float32')
                    dimension = st.session_state.embeddings.shape[1]
                    faiss_index = faiss.IndexFlatL2(dimension)
                    faiss_index.add(st.session_state.embeddings)
                    st.session_state.index = faiss_index
                    
                    # Phase 2ë¥¼ ìœ„í•œ ë°ì´í„° ë° ì¸ë±ìŠ¤ êµ¬ì„±
                    st.session_state.retriever_pool_df = retriever_pool_df
                    
                    # Phase 2 ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” ì ì ˆí•œ ë°ì´í„°ë¡œ í›ˆë ¨í•´ì•¼ í•¨)
                    phase2_index = faiss.IndexFlatL2(dimension)
                    phase2_index.add(st.session_state.embeddings)
                    st.session_state.phase2_index = phase2_index
                    
                st.success("ì„ë² ë”© ìƒì„± ë° ì¸ë±ìŠ¤ êµ¬ì„± ì™„ë£Œ!")
            else:
                st.info("ì•„ì§ ì¸ë±ìŠ¤ê°€ ë§Œë“¤ì–´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. [ì„ë² ë”© ì‚¬ì „ ê³„ì‚°]ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    # ----- ê³µí†µ ì„¤ì • (ì‚¬ì´ë“œë°” ë“±) -----
    with st.sidebar:
        st.header("ğŸ“Š ë¶„ì„ ì„¤ì •")
        k_similar = st.slider("ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ìˆ˜", min_value=1, max_value=10, value=5)
        
        # Phase 2 ê´€ë ¨ ì‚¬ì´ë“œë°” ì„¤ì •
        st.header("ğŸ“‹ ê°œì„ ëŒ€ì±… ì„¤ì •")
        target_language = st.selectbox(
            "ê°œì„ ëŒ€ì±… ì–¸ì–´ ì„ íƒ", 
            options=language_options,
            index=0
        )

    # íƒ­ 2) ì‚¬ìš©ì ì…ë ¥ ì˜ˆì¸¡
    with tabs[1]:
        st.subheader("ì‚¬ìš©ì ì…ë ¥ ì˜ˆì¸¡")

        if st.session_state.index is None:
            st.warning("ë¨¼ì € [ì„ë² ë”© ì‚¬ì „ ê³„ì‚°] íƒ­ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        else:
            with st.form("user_input_form"):
                user_work = st.text_input("ì‘ì—…í™œë™ (ì‚¬ìš©ì ì…ë ¥):", key="form_user_work")
                user_risk = st.text_input("ìœ í•´ìœ„í—˜ìš”ì¸ (ì‚¬ìš©ì ì…ë ¥):", key="form_user_risk")
                submitted = st.form_submit_button("ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸°")

            if submitted:
                if not user_work or not user_risk:
                    st.warning("ì‘ì—…í™œë™ê³¼ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    query_text = f"{user_work} {user_risk}"
                    
                    # ì¿¼ë¦¬ ì„ë² ë”©
                    query_embedding = embed_texts_with_openai([query_text])[0]
                    query_embedding_array = np.array([query_embedding], dtype='float32')
                    
                    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
                    distances, indices = st.session_state.index.search(query_embedding_array, k_similar)
                    retrieved_docs = retriever_pool_df.iloc[indices[0]]

                    # GPT í”„ë¡¬í”„íŠ¸ ìƒì„± & í˜¸ì¶œ
                    prompt = construct_prompt(retrieved_docs, query_text)
                    generated_output = generate_with_gpt4(prompt)

                    st.markdown(f"**ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬**: {query_text}")
                    parse_result = parse_gpt_output(generated_output)
                    if parse_result is not None:
                        f_val, i_val, t_val = parse_result
                        st.write(f"GPT ì˜ˆì¸¡ â†’ ë¹ˆë„: {f_val}, ê°•ë„: {i_val}, T: {t_val}")
                    else:
                        st.write(f"GPT ì˜ˆì¸¡(ì›ë¬¸): {generated_output}")

    # íƒ­ 3) ìƒ˜í”Œ ì˜ˆì¸¡
    with tabs[2]:
        st.subheader("ìƒ˜í”Œ ì˜ˆì¸¡ (ìƒìœ„ 3ê°œë§Œ í‘œì‹œ)")

        if st.session_state.index is None:
            st.warning("ë¨¼ì € [ì„ë² ë”© ì‚¬ì „ ê³„ì‚°] íƒ­ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        else:
            sample_df = test_df.iloc[:3].copy().reset_index(drop=True)

            for idx, row in sample_df.iterrows():
                st.markdown(f"**ìƒ˜í”Œ {idx+1}**")
                st.markdown(f"- ì‘ì—…í™œë™: {row['ì‘ì—…í™œë™ ë° ë‚´ìš©']}")
                st.markdown(f"- ìœ í•´ìœ„í—˜ìš”ì¸: {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}")
                st.markdown(f"- ì‹¤ì œ ë¹ˆë„: {row['ë¹ˆë„']}, ì‹¤ì œ ê°•ë„: {row['ê°•ë„']}, ì‹¤ì œ T: {row['T']}")

                query_text = f"{row['ì‘ì—…í™œë™ ë° ë‚´ìš©']} {row['ìœ í•´ìœ„í—˜ìš”ì¸ ë° í™˜ê²½ì¸¡ë©´ ì˜í–¥']}"

                # ì¿¼ë¦¬ ì„ë² ë”©
                query_embedding = embed_texts_with_openai([query_text])[0]
                query_embedding_array = np.array([query_embedding], dtype='float32')

                # FAISS ê²€ìƒ‰
                distances, indices = st.session_state.index.search(query_embedding_array, k_similar)
                retrieved_docs = retriever_pool_df.iloc[indices[0]]

                # GPT í˜¸ì¶œ
                prompt = construct_prompt(retrieved_docs, query_text)
                generated_output = generate_with_gpt4(prompt)

                # GPT ì˜ˆì¸¡ íŒŒì‹±
                parse_result = parse_gpt_output(generated_output)
                if parse_result is not None:
                    f_val, i_val, t_val = parse_result
                    st.write(f"**GPT ì˜ˆì¸¡** â†’ ë¹ˆë„: {f_val}, ê°•ë„: {i_val}, T: {t_val}")
                else:
                    st.write(f"**GPT ì˜ˆì¸¡**: {generated_output}")
                
                st.markdown("---")

            st.markdown("### ì˜ˆì¸¡ ì™„ë£Œ")
            st.info("ìƒê¸° í‘œì‹œëœ ìƒ˜í”Œ 3ê°œëŠ” ì‹¤ì œ ë°ì´í„°ì…‹ì—ì„œ ì¼ë¶€ë§Œ ë°œì·Œí•œ ì˜ˆì‹œì…ë‹ˆë‹¤.")
            
    # íƒ­ 4) ê°œì„ ëŒ€ì±… ìƒì„± (Phase 2 ì¶”ê°€)
    with tabs[3]:
        st.subheader("ê°œì„ ëŒ€ì±… ìƒì„±")
        
        if st.session_state.phase2_index is None:
            st.warning("ë¨¼ì € [ì„ë² ë”© ì‚¬ì „ ê³„ì‚°] íƒ­ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        else:
            st.write("ì‘ì—…í™œë™ê³¼ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ì…ë ¥í•˜ì—¬ ê°œì„ ëŒ€ì±…ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            
            with st.form("improvement_form"):
                p2_user_work = st.text_input("ì‘ì—…í™œë™:", key="p2_user_work")
                p2_user_risk = st.text_input("ìœ í•´ìœ„í—˜ìš”ì¸:", key="p2_user_risk")
                p2_user_freq = st.number_input("ê°œì„  ì „ ë¹ˆë„ (1-5):", min_value=1, max_value=5, value=3)
                p2_user_intensity = st.number_input("ê°œì„  ì „ ê°•ë„ (1-5):", min_value=1, max_value=5, value=3)
                p2_submitted = st.form_submit_button("ê°œì„ ëŒ€ì±… ìƒì„±í•˜ê¸°")
            
            if p2_submitted:
                if not p2_user_work or not p2_user_risk:
                    st.warning("ì‘ì—…í™œë™ê³¼ ìœ í•´ìœ„í—˜ìš”ì¸ì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    # ê°œì„  ì „ T ê°’ ê³„ì‚°
                    T_before = p2_user_freq * p2_user_intensity
                    
                    with st.spinner('ê°œì„ ëŒ€ì±…ì„ ìƒì„±í•˜ëŠ” ì¤‘...'):
                        # GPTë¥¼ ì´ìš©í•œ ê°œì„ ëŒ€ì±… ìƒì„±
                        gpt_raw = predict_improvement(
                            activity_text=p2_user_work,
                            hazard_text=p2_user_risk,
                            top_k=k_similar,
                            embedding_model="text-embedding-3-small",
                            target_language=target_language
                        )
                        
                        # ê²°ê³¼ íŒŒì‹±
                        parsed_result = parse_gpt_response(gpt_raw)
                        
                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown("## ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("### ê°œì„  ì „")
                        st.markdown(f"- **ì‘ì—…í™œë™**: {p2_user_work}")
                        st.markdown(f"- **ìœ í•´ìœ„í—˜ìš”ì¸**: {p2_user_risk}")
                        st.markdown(f"- **ë¹ˆë„**: {p2_user_freq}")
                        st.markdown(f"- **ê°•ë„**: {p2_user_intensity}")
                        st.markdown(f"- **T**: {T_before}")
                        st.markdown(f"- **ë“±ê¸‰**: {determine_grade(T_before)}")
                    
                    with col2:
                        st.markdown("### ê°œì„  í›„ (GPT ì˜ˆì¸¡)")
                        if parsed_result:
                            improvement_plan = parsed_result.get("ê°œì„ ëŒ€ì±… ë° ì„¸ë¶€ê´€ë¦¬ë°©ì•ˆ", "")
                            improved_freq = parsed_result.get("ê°œì„  í›„ ë¹ˆë„", 1)
                            improved_intensity = parsed_result.get("ê°œì„  í›„ ê°•ë„", 1)
                            improved_T = parsed_result.get("ê°œì„  í›„ T", 1)
                            
                            # T ê°’ ê²€ì¦ (ë¹ˆë„ * ê°•ë„ = T)
                            if improved_freq * improved_intensity != improved_T:
                                improved_T = improved_freq * improved_intensity
                                st.warning("ê°œì„  í›„ T ê°’ì´ ë¹ˆë„ * ê°•ë„ì™€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ ë‹¤ì‹œ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.")
                            
                            rrr = compute_rrr(T_before, improved_T)
                            
                            st.markdown(f"- **ê°œì„  í›„ ë¹ˆë„**: {improved_freq}")
                            st.markdown(f"- **ê°œì„  í›„ ê°•ë„**: {improved_intensity}")
                            st.markdown(f"- **ê°œì„  í›„ T**: {improved_T}")
                            st.markdown(f"- **ë“±ê¸‰**: {determine_grade(improved_T)}")
                            st.markdown(f"- **ìœ„í—˜ ê°ì†Œìœ¨**: {rrr:.2f}%")
                        else:
                            st.error("ê°œì„ ëŒ€ì±… ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. GPT ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
